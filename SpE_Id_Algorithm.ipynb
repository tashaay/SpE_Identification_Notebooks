{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c36fa6d4-8154-4024-94e2-310a62aa606f",
   "metadata": {},
   "source": [
    "# FINAL ALGORITHM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf0dd2-e054-420c-8e68-d57fd731d191",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### USE THIS ONE ###\n",
    "\n",
    "# Main notebook for Sporadic E detection algorithm for WACCM data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf0798-0c78-465f-b81a-bd2509a629e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' INSTRUCTIONS :\n",
    "\n",
    "- Run all notebooks from top to bottom to execute the code. \n",
    "\n",
    "- Things to check/change each time:\n",
    "\n",
    "    Save_results function:\n",
    "        - filename_append: Identifier for to the criteria set used to identify Es layers. \n",
    "                           '0.25sigma_2xMpza_1xpeak' is the string I used for the final criteria used for the paper\n",
    "        - output_file: Define where to save the output. \n",
    "\n",
    "    Main Calculations:\n",
    "        - run_name: Defines what model run/input data is used. Permitted to be set values (Jianfei_run, Wuhu_IonTr_run, Wuhu_IonTr_run_6m, SMin, SMax) currently. More could be added in a similar way as needed\n",
    "        - ds_months_sets, Monthstr_sets, season_set : together define what seasons you're running the code for. Can be one or multiple. Common combos are left commented out for easy use\n",
    "        - Criteria calculations: If changing the criteria for some reason, they need to be changed where it says \"CRITERIA & Es Identifiation Calculations\". \n",
    "                                 These calculations are repeated twice for calculations in local time and lon, so the criteria need to be changed in both places\n",
    "\n",
    "Things to note:\n",
    "- If a nc file exists already with the same name it will throw an error when trying to save\n",
    "- Apologies for the rubbish variable names. If unsure what something is, check the attributes/dimensions in the nc variable or the code calculating the variable... Search for the variable and follow the code through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd32239-4e8b-4073-b414-d911bbf51062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cftime\n",
    "import nc_time_axis\n",
    "import matplotlib.pyplot as plt \n",
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import cftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3a368d-5e53-4d16-b3c1-019a02a9af10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Define_variables Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507d5449-e6c9-4c5f-91c7-f14c7c83e213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initialising arrays since they're first defined within the loop\n",
    "\n",
    "def define_variables(lev_shape, time_shape, lat_shape, lon_shape, LTshape, time_it_shape, ds_months_shape, newlat_shape, intlat_shape, crit_freq_on):\n",
    "\n",
    "    Mptdens_sh = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Metal density in local time\n",
    "    Mptdens_diff = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)   #Difference between Metal density and average for the timeslice\n",
    "\n",
    "    SpEs_sh_nan = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape))  \n",
    "    SpEs_sh_nan[:] = np.NaN #An array the same size as SpEs_sh filled with NaNs. Used for seletion criteria calculation\n",
    "\n",
    "    #Mptdens_avg_temp = np.empty((lev_shape, lat_shape, 3, time_it_shape, ds_months_shape), dtype=float)  #Temporary array used in calculation rebinning from 10min -> 30 min LT bins\n",
    "    Mptdens_avg_b = np.empty((lev_shape, lat_shape, LTshape, time_it_shape, ds_months_shape), dtype=float)    #10 min bins (144 lon) -> 30 min bins (48 lon)\n",
    "    #-------------------------------------------------\n",
    "    Mptdens_avv1_b = np.empty((lev_shape, newlat_shape, time_it_shape, ds_months_shape), dtype=float)   #Mptdens_avv1 interpolated onto 1' lat array\n",
    "\n",
    "    Mptdens_avv1_b_5d = np.empty((lev_shape, intlat_shape, time_it_shape, ds_months_shape), dtype=float) #Average M+ density in 5' lat slices (as ft of lev)\n",
    "    max_Mptdens_avv1_b_5d = np.empty((intlat_shape, time_it_shape, ds_months_shape), dtype=float)        #Max of Mptdens_avv1_b_5d over lev dim\n",
    "\n",
    "    #Equivalent to Mptdens_avv1_b_5d and max_Mptdens_avv1_b_5d but assigned to the correct index on a normal 96-long lat axis (so can use these in selectin criteria)\n",
    "    Mptdens_avv1b5d_l = np.empty((lev_shape, lat_shape, time_it_shape, ds_months_shape), dtype=float) \n",
    "    max_Mptdens_avv1b5d_l = np.empty((lat_shape, time_it_shape, ds_months_shape), dtype=float) \n",
    "    #-------------------------------------------------\n",
    "    Mptdens_avg_bb = np.empty((lev_shape, newlat_shape, LTshape, time_it_shape, ds_months_shape), dtype=float)  #binned into 30 min LT bins and binned into 1' lat slices\n",
    "\n",
    "\n",
    "    Mptdens_avg_bb_5d = np.empty(  (lev_shape,intlat_shape, LTshape, time_it_shape, ds_months_shape )   , dtype=float )  #Mptdens_avg_b binned into 30 min LT bins and averaged in 5' lat slices\n",
    "    Mptdens_avg_bb_5d_avg = np.empty((lev_shape, intlat_shape, LTshape, ds_months_shape), dtype=float)   #Monthly avg at each height/lat/lon\n",
    "    Mptdens_avg_bb_5d_avglev = np.empty((intlat_shape, LTshape, ds_months_shape), dtype=float)  #Monthly avg over all levs\n",
    "    Mptdens_avg_bb_5d_dsavg = np.empty((lev_shape, intlat_shape, LTshape), dtype = float)   #Dataset avg at each height/lat/lon\n",
    "    Mptdens_avg_bb_5d_dsavglev = np.empty((intlat_shape, LTshape), dtype = float) #Dataset avg over all levs\n",
    "\n",
    "\n",
    "    if crit_freq_on==1:\n",
    "        edens_sh = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #e density in local time\n",
    "        SpEs_e = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #The e density where SpEs have been identified using Fe+ density  \n",
    "        maxSpEs__e = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #max of SpEs_e in cm-3\n",
    "        maxSpEs_e = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #max of SpEs_e in m-3\n",
    "        foEs__m = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Critical freq in Hz (calculated using max e- density over lev dim in m-3)\n",
    "        foEs_m = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Critical freq in MHz (calculated using max e- density over lev dim in m-3)\n",
    "        foEs_m_av = np.empty((lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Avg of foEs_m over lev dimension\n",
    "        foEs_m_av_mth = np.empty((lat_shape, lon_shape, ds_months_shape), dtype = float) #Average of foEs_m_av over month\n",
    "        foEs_m_av_ds = np.empty((lat_shape, lon_shape), dtype = float) #AVerage of foEs_m_av_mth over dataset (e.g. 3mth)  \n",
    "\n",
    "    SpEs = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #SpEs occurence frequency \n",
    "    SpEs_freq = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape)) #SpE occurence in each grid space as 1s/0s\n",
    "    SpEs_freq_time = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape))     #total SpE occurences in 2 week time period\n",
    "    SpEs_Occ_Freq = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)  # SpEs_freq_time / no of timesteps -> occ freq as a %\n",
    "    #SpEs_Occ_Freq_temp = np.empty((lev_shape, lat_shape, 3, time_it_shape, ds_months_shape), dtype=float)  #Temporary array used in the calculation for 10 min bins (144 lon) -> 30 min bins (48 lon)\n",
    "    \n",
    "    SpEs_freq_altsum = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape))\n",
    "    SpEs_freq_altsum_time = np.empty((lat_shape, lon_shape, time_it_shape, ds_months_shape))\n",
    "    SpEs_Occ_Freq_ll =  np.empty((lat_shape, lon_shape, time_it_shape, ds_months_shape))\n",
    "    SpEs_Occ_Freq_llb =  np.empty((lat_shape, LTshape, time_it_shape, ds_months_shape))\n",
    "    SpEs_Occ_Freq_llba =  np.empty((lat_shape, LTshape, ds_months_shape))\n",
    "    SpEs_Occ_Freq_llbav = np.empty((lat_shape, LTshape))\n",
    "            \n",
    "    #-------------------------------------------------\n",
    "    SpEs_Occ_Fr_b = np.empty((lev_shape, lat_shape, LTshape, time_it_shape, ds_months_shape), dtype=float)    #10 min bins (144 lon) -> 30 min bins (48 lon)\n",
    "    SpEs_Occ_Fr_b_avg = np.empty((lev_shape, lat_shape, LTshape, ds_months_shape), dtype = float)  #Monthly avg at each height/lat/lon\n",
    "    SpEs_Occ_Fr_b_dsavg = np.empty((lev_shape, lat_shape, LTshape), dtype = float)   #Dataset avg at each height/lat/lon\n",
    "    SpEs_Occ_Fr_b_avgLT = np.empty((lev_shape, lat_shape, ds_months_shape), dtype = float)  #Monthly avg over all LTs\n",
    "    SpEs_Occ_Fr_b_dsavgLT = np.empty((lev_shape, lat_shape), dtype = float)  #dataset avg over all LTs\n",
    "    #-------------------------------------------------\n",
    "    SpEs_Occ_Fr_bb = np.empty((lev_shape, newlat_shape, LTshape, time_it_shape, ds_months_shape), dtype=float) #SpEs_Occ_Fr_b interpolated onto newlat grid 1' spacing (180 long) (was 1.89')\n",
    "\n",
    "    SpEs_Occ_Fr_bb_5d = np.empty(  (lev_shape,intlat_shape, LTshape, time_it_shape, ds_months_shape )   , dtype=float )  #SpEs_Occ_Fr_bb averaged into 5' lat slices\n",
    "    SpEs_Occ_Fr_bb_5d_avg = np.empty((lev_shape, intlat_shape, LTshape, ds_months_shape), dtype=float)   #Monthly avg at each height/lat/lon\n",
    "    SpEs_Occ_Fr_bb_5d_dsavg = np.empty((lev_shape, intlat_shape, LTshape), dtype = float)   #Dataset avg at each height/lat/lon\n",
    "    \n",
    "    SpEs_Occ_Fr_bb_5d_dsavglev = np.empty((intlat_shape, LTshape), dtype = float) #Dataset avg over all levs\n",
    "\n",
    "    #Lat-Lon\n",
    "    Mptdensns = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)  #Mptdens not shifted into local time\n",
    "    Mptdens_nsavg = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)\n",
    "    Mptdens_nsstd = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)\n",
    "    Mptdens_nsdiff = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)   #Difference between Metal density and average\n",
    "    Mptdens_nsavv1_b = np.empty((lev_shape, newlat_shape, time_it_shape, ds_months_shape), dtype=float)   #Mptdens_nsavv1 interpolated onto 1' lat array\n",
    "    Mptdens_nsavv1_b_5d = np.empty((lev_shape, intlat_shape, time_it_shape, ds_months_shape), dtype=float) #Average M+ density in 5' lat slices (as ft of lev)\n",
    "    max_Mptdens_nsavv1_b_5d = np.empty((intlat_shape, time_it_shape, ds_months_shape), dtype=float)        #Max of Mptdens_nsavv1_b_5d over lev dim\n",
    "    #Equivalent to Mptdens_nsavv1_b_5d and max_Mptdens_nsavv1_b_5d but assigned to the correct index on a normal 96-long lat axis (so can use these in selectin criteria):\n",
    "    Mptdens_nsavv1b5d_l = np.empty((lev_shape, lat_shape, time_it_shape, ds_months_shape), dtype=float) \n",
    "    max_Mptdens_nsavv1b5d_l = np.empty((lat_shape, time_it_shape, ds_months_shape), dtype=float) \n",
    "\n",
    "    if crit_freq_on==1:\n",
    "        edensns = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)  \n",
    "        SpEs_nse = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #The e density where SpEs have been identified using Fe+ density\n",
    "        maxSpEs__nse = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #max of SpEs_e in cm-3\n",
    "        maxSpEs_nse = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #max of SpEs_e in m-3\n",
    "        foEsns__m = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Critical freq in Hz (calculated using max e- density over lev dim in m-3)\n",
    "        foEsns_m = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Critical freq in MHz (calculated using max e- density over lev dim in m-3)\n",
    "        foEsns_m_av = np.empty((lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #Avg of foEs_m over lev dimension\n",
    "        foEsns_m_av_mth = np.empty((lat_shape, lon_shape, ds_months_shape), dtype = float) #Average of foEs_m_av over month\n",
    "        foEsns_m_av_ds = np.empty((lat_shape, lon_shape), dtype = float) #AVerage of foEs_m_av_mth over dataset (e.g. 3mth)  \n",
    "\n",
    "    SpEsns = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) #SpEs occurence frequency   \n",
    "    SpEsns_freq_bool = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape)) #SpE occurence in each grid space as True/False \n",
    "    SpEsns_freq = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape)) #SpE occurence in each grid space as 1s/0s\n",
    "    SpEsns_freq_time = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape))     #total SpE occurences in 2 week time period\n",
    "    SpEsns_Occ_Freq = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)  # SpEs_freq_time / no of timesteps -> occ freq as a %\n",
    "    SpEsns_Occ_Fr_avg = np.empty((lev_shape, lat_shape, lon_shape, ds_months_shape), dtype = float) \n",
    "    SpEsns_Occ_Fr_dsavg = np.empty((lev_shape, lat_shape, lon_shape), dtype = float)   \n",
    "\n",
    "    SpEsns_freq_altsum = np.empty((time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape))\n",
    "    SpEsns_freq_altsum_time = np.empty((lat_shape, lon_shape, time_it_shape, ds_months_shape))\n",
    "    SpEsns_Occ_Freq_ll =  np.empty((lat_shape, lon_shape, time_it_shape, ds_months_shape))\n",
    "    SpEsns_Occ_Freq_lla =  np.empty((lat_shape, lon_shape, ds_months_shape))\n",
    "    SpEsns_Occ_Freq_llav = np.empty((lat_shape, lon_shape))\n",
    "    \n",
    "    altavg = np.empty((126, ds_months_shape), dtype = float) \n",
    "    altavg_sl = np.empty((lev_shape, ds_months_shape), dtype = float) \n",
    "    \n",
    "    alt_sl_avg = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) \n",
    "    alt_sl_aavg = np.empty((lev_shape, lat_shape, lon_shape, ds_months_shape), dtype = float) \n",
    "    alt_sl_aaavg = np.empty((lev_shape, lat_shape, lon_shape), dtype = float) #(20,96,144)      #lev,lat,lon\n",
    "\n",
    "    alt_sl_sh = np.empty((lev_shape, time_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float) \n",
    "    alt_sl_sh_avg = np.empty((lev_shape, lat_shape, lon_shape, time_it_shape, ds_months_shape), dtype = float)    \n",
    "    #alt_sl_sh_avg_temp = np.empty( (lev_shape, lat_shape, 3, time_it_shape, ds_months_shape), dtype = float) \n",
    "    alt_sl_sh_avg_b = np.empty( (lev_shape, lat_shape, LTshape, time_it_shape, ds_months_shape) , dtype = float) \n",
    "    alt_sl_sh_avg_b_avg = np.empty( (lev_shape, lat_shape, LTshape, ds_months_shape) , dtype = float)\n",
    "    alt_sl_sh_avg_b_dsavg = np.empty( (lev_shape, lat_shape, LTshape) , dtype = float)\n",
    "    alt_sl_sh_avg_b_avgLT = np.empty( (lev_shape, lat_shape, ds_months_shape) , dtype = float)\n",
    "    alt_sl_sh_avg_b_dsavgLT = np.empty( (lev_shape, lat_shape) , dtype = float)\n",
    "    alt_sl_sh_avg_bb_5d = np.empty(  (lev_shape, intlat_shape, LTshape, time_it_shape, ds_months_shape )   , dtype=float ) #Mptdens_avg_b binned into 30 min LT bins and averaged in 5' lat slices\n",
    "    alt_sl_sh_avg_bb_5d_avg = np.empty(  (lev_shape, intlat_shape, LTshape, ds_months_shape )   , dtype=float )\n",
    "    alt_sl_sh_avg_bb = np.empty((lev_shape, newlat_shape, LTshape, time_it_shape, ds_months_shape), dtype=float)  #binned into 30 min LT bins and binned into 1' lat slices\n",
    "\n",
    "    alt_sl_sh_avg_bb_5d_dsavg = np.empty((lev_shape, intlat_shape, LTshape), dtype = float)   #Dataset avg at each height/lat/lt\n",
    "    \n",
    "    \n",
    "    if crit_freq_on == 1:\n",
    "        return Mptdens_sh, Mptdens_diff, SpEs_sh_nan, Mptdens_avg_b, Mptdens_avv1_b, Mptdens_avv1_b_5d, max_Mptdens_avv1_b_5d, Mptdens_avv1b5d_l, max_Mptdens_avv1b5d_l, Mptdens_avg_bb, Mptdens_avg_bb_5d, Mptdens_avg_bb_5d_avg, Mptdens_avg_bb_5d_avglev, Mptdens_avg_bb_5d_dsavg, Mptdens_avg_bb_5d_dsavglev, edens_sh, SpEs_e, maxSpEs__e, maxSpEs_e, foEs__m, foEs_m, foEs_m_av, foEs_m_av_mth, foEs_m_av_ds, SpEs, SpEs_freq, SpEs_freq_time, SpEs_Occ_Freq, SpEs_Occ_Fr_b, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avgLT, SpEs_Occ_Fr_b_dsavgLT, SpEs_Occ_Fr_bb, SpEs_Occ_Fr_bb_5d, SpEs_Occ_Fr_bb_5d_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEs_Occ_Fr_bb_5d_dsavglev, Mptdensns, Mptdens_nsavg, Mptdens_nsstd, Mptdens_nsdiff, Mptdens_nsavv1_b, Mptdens_nsavv1_b_5d, max_Mptdens_nsavv1_b_5d, Mptdens_nsavv1b5d_l, max_Mptdens_nsavv1b5d_l, edensns, SpEs_nse, maxSpEs__nse, maxSpEs_nse, foEsns__m, foEsns_m, foEsns_m_av, foEsns_m_av_mth, foEsns_m_av_ds, SpEsns, SpEsns_freq_bool, SpEsns_freq, SpEsns_freq_time, SpEsns_Occ_Freq, SpEsns_Occ_Fr_avg, SpEsns_Occ_Fr_dsavg, alt_sl_avg, alt_sl_aavg, alt_sl_aaavg, alt_sl_sh, alt_sl_sh_avg, alt_sl_sh_avg_b, alt_sl_sh_avg_b_avg, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_b_avgLT, alt_sl_sh_avg_bb_5d, alt_sl_sh_avg_bb_5d_avg, alt_sl_sh_avg_bb_5d_dsavg, alt_sl_sh_avg_bb\n",
    "\n",
    "    else:\n",
    "        # Calculate variables when crit_freq_on is 0:\n",
    "        edens_sh = None\n",
    "        SpEs_e = None\n",
    "        maxSpEs__e = None\n",
    "        maxSpEs_e = None\n",
    "        foEs__m = None\n",
    "        foEs_m = None\n",
    "        foEs_m_av = None\n",
    "        foEs_m_av_mth = None\n",
    "        foEs_m_av_ds = None\n",
    "        \n",
    "        edensns = None\n",
    "        SpEs_nse = None\n",
    "        maxSpEs__nse = None\n",
    "        maxSpEs_nse = None\n",
    "        foEsns__m = None\n",
    "        foEsns_m = None\n",
    "        foEsns_m_av = None\n",
    "        foEsns_m_av_mth = None\n",
    "        foEsns_m_av_ds = None\n",
    "\n",
    "        return Mptdens_sh, Mptdens_diff, SpEs_sh_nan, Mptdens_avg_b, Mptdens_avv1_b, Mptdens_avv1_b_5d, max_Mptdens_avv1_b_5d, Mptdens_avv1b5d_l, max_Mptdens_avv1b5d_l, Mptdens_avg_bb, Mptdens_avg_bb_5d, Mptdens_avg_bb_5d_avg, Mptdens_avg_bb_5d_avglev, Mptdens_avg_bb_5d_dsavg, Mptdens_avg_bb_5d_dsavglev, edens_sh, SpEs_e, maxSpEs__e, maxSpEs_e, foEs__m, foEs_m, foEs_m_av, foEs_m_av_mth, foEs_m_av_ds, SpEs, SpEs_freq, SpEs_freq_time, SpEs_Occ_Freq, SpEs_Occ_Fr_b, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avgLT, SpEs_Occ_Fr_b_dsavgLT, SpEs_Occ_Fr_bb, SpEs_Occ_Fr_bb_5d, SpEs_Occ_Fr_bb_5d_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEs_Occ_Fr_bb_5d_dsavglev, Mptdensns, Mptdens_nsavg, Mptdens_nsstd, Mptdens_nsdiff, Mptdens_nsavv1_b, Mptdens_nsavv1_b_5d, max_Mptdens_nsavv1_b_5d, Mptdens_nsavv1b5d_l, max_Mptdens_nsavv1b5d_l, edensns, SpEs_nse, maxSpEs__nse, maxSpEs_nse, foEsns__m, foEsns_m, foEsns_m_av, foEsns_m_av_mth, foEsns_m_av_ds, SpEsns, SpEsns_freq_bool, SpEsns_freq, SpEsns_freq_time, SpEsns_Occ_Freq, SpEsns_Occ_Fr_avg, SpEsns_Occ_Fr_dsavg, altavg, altavg_sl, alt_sl_avg, alt_sl_aavg, alt_sl_aaavg, alt_sl_sh, alt_sl_sh_avg, alt_sl_sh_avg_b, alt_sl_sh_avg_b_avg, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_b_avgLT, alt_sl_sh_avg_bb_5d, alt_sl_sh_avg_bb_5d_avg, alt_sl_sh_avg_bb_5d_dsavg, alt_sl_sh_avg_bb, SpEs_freq_altsum, SpEs_freq_altsum_time, SpEs_Occ_Freq_ll, SpEs_Occ_Freq_llb, SpEs_Occ_Freq_llba, SpEs_Occ_Freq_llbav, SpEsns_freq_altsum,SpEsns_freq_altsum_time,SpEsns_Occ_Freq_ll,SpEsns_Occ_Freq_lla,SpEsns_Occ_Freq_llav\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e47766-c818-452d-afe8-5a942c807e2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save_results Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69f3e01-34ba-4374-9444-f144095ebc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save output from SpE algorithm to nc files for each season\n",
    "\n",
    "def save_results(run_name, Monthfolderstr, lev, lev_sl, timear, lat, intlat, lon, LTar, LTlong, time_ar_2wk, ds_months, Zavg_sl, altavg, altavg_sl, times_str_min, times_str_max, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEsns_Occ_Fr_dsavg, SpEs, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_bb_5d_dsavg, Mptdens_avv1_b_5d, Mptdens_std, Mptdens_nsstd, SpEsns_freq_time, SpEs_freq_time, Mptdens_avg, Mptdens_nsdiff, Mptdens_nsavg, SpEs_Occ_Freq_llbav, SpEsns_Occ_Freq_llav, SpEsns_Occ_Freq_lat ):\n",
    "    \n",
    "    filename_append = '0.25sigma_2xMpza_1xpeak' \n",
    "    \n",
    "    output_file = f'Nc_Files/SpE_Output/SMin/{str(run_name)}_SpE_Output_{str(Monthfolderstr)}_90-150km_{filename_append}.nc'\n",
    "\n",
    "\n",
    "    \n",
    "    with nc.Dataset(output_file, 'w') as dataset:\n",
    "\n",
    "        # Create dimensions\n",
    "        dataset.createDimension('lev', len(lev))\n",
    "        dataset.createDimension('lev_sl', len(lev_sl))\n",
    "        dataset.createDimension('time', len(timear))\n",
    "        dataset.createDimension('lat', len(lat))\n",
    "        dataset.createDimension('latsl', len(intlat))\n",
    "        dataset.createDimension('lon', len(lon))\n",
    "        dataset.createDimension('LT', len(LTar))\n",
    "        dataset.createDimension('LT_L', len(LTlong))\n",
    "        dataset.createDimension('timesl', 2)\n",
    "        dataset.createDimension('mth', 3)\n",
    "\n",
    "        # Create coordinate variables\n",
    "        lev_coord = dataset.createVariable('lev', 'f8', ('lev',))\n",
    "        lev_sl_coord = dataset.createVariable('lev_sl', 'f8', ('lev_sl',))\n",
    "        time_coord = dataset.createVariable('time', 'f8', ('time',))\n",
    "        lat_coord = dataset.createVariable('lat', 'f8', ('lat',))\n",
    "        latsl_coord = dataset.createVariable('latsl', 'f8', ('latsl',))\n",
    "        lon_coord = dataset.createVariable('lon', 'f8', ('lon',))\n",
    "        LT_coord = dataset.createVariable('LT', 'f8', ('LT',))\n",
    "        LT_L_coord = dataset.createVariable('LT_L', 'f8', ('LT_L',))\n",
    "        timesl_coord = dataset.createVariable('timesl', 'f8', ('timesl',))\n",
    "        mth_coord = dataset.createVariable('mth', 'f8', ('mth',))\n",
    "\n",
    "        # Assign values to coordinate variables\n",
    "        lev_coord[:] = lev[:]\n",
    "        lev_sl_coord[:] = lev_sl[:]\n",
    "        time_coord[:] = timear[:]\n",
    "        lat_coord[:] = lat[:]\n",
    "        latsl_coord[:] = intlat[:]\n",
    "        lon_coord[:] = lon[:]\n",
    "        LT_coord[:] = LTar[:]  \n",
    "        LT_L_coord[:] = LTlong[:]   \n",
    "        timesl_coord[:] = time_ar_2wk[:]\n",
    "        mth_coord[:] = ds_months[:]\n",
    "\n",
    "        \n",
    "        # Add attributes to coordinate variables\n",
    "        lev_coord.long_name = 'vertical level'\n",
    "        lev_coord.units = 'hPa'\n",
    "        \n",
    "        lev_sl_coord.long_name = 'vertical level sliced lev[42:60] (~90-130km geometric alt)'\n",
    "        lev_sl_coord.units = 'hPa'\n",
    "        \n",
    "        time_coord.long_name = 'time'\n",
    "        time_coord.units = 'days since start of 2 week time slice (0-335)'\n",
    "        \n",
    "        lat_coord.long_name = 'latitude'\n",
    "        lat_coord.units = 'degrees_north'\n",
    "        \n",
    "        latsl_coord.long_name = 'latitude grid sliced in 5deg slices (array 0-35)'\n",
    "        latsl_coord.units = 'degrees_north'\n",
    "        \n",
    "        lon_coord.long_name = 'longitude'\n",
    "        lon_coord.units = 'degrees_east'\n",
    "        \n",
    "        LT_coord.long_name = 'Local Time, 48 x 30 min bins'\n",
    "        LT_coord.units = 'hours'\n",
    "        \n",
    "        LT_L_coord.long_name = 'Local Time, 144 bins (WACCM resolution)'\n",
    "        LT_L_coord.units = 'hours'\n",
    "        \n",
    "        timesl_coord.long_name = 'time slice identifier, 2 timeslices per month'\n",
    "        timesl_coord.units = 'arrary [0,1]'\n",
    "        \n",
    "        mth_coord.long_name = 'month identifier for 3 month seasonal period'\n",
    "        #mth_coord.units = ''\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create and save arrays as variables\n",
    "\n",
    "        Zavg_sl_v = dataset.createVariable('Zavg_sl', 'f8', ('lev_sl',))\n",
    "        Zavg_sl_v[:] = Zavg_sl[:]\n",
    "        Zavg_sl_v.setncattr('units', 'km')\n",
    "        Zavg_sl_v.setncattr('description', 'Global average Geopotential height, sliced between 90-130km')\n",
    "\n",
    "        altavg_v = dataset.createVariable('altavg', 'f8', ('lev',))\n",
    "        altavg_v[:] = altavg[:]\n",
    "        altavg_v.setncattr('units', 'km')\n",
    "        altavg_v.setncattr('description', 'Global average geometric altitude')\n",
    "        \n",
    "        altavg_sl_v = dataset.createVariable('altavg_sl', 'f8', ('lev_sl',))\n",
    "        altavg_sl_v[:] = altavg_sl[:]\n",
    "        altavg_sl_v.setncattr('units', 'km')\n",
    "        altavg_sl_v.setncattr('description', 'Global average geometric altitude, sliced between 90-130km')\n",
    "\n",
    "        times_str_min_v = dataset.createVariable('times_str_min', 'S21', ('mth', 'timesl'))\n",
    "        times_str_min_v[:] = times_str_min[:]\n",
    "        times_str_min_v.setncattr('description', 'Timeslice start datetime')\n",
    "\n",
    "        times_str_max_v = dataset.createVariable('times_str_max', 'S21', ('mth', 'timesl'))\n",
    "        times_str_max_v[:] = times_str_max[:]\n",
    "        times_str_max_v.setncattr('description', 'Timeslice end datetime')\n",
    "\n",
    "        SpEsns_Occ_Freq_lat_v = dataset.createVariable('SpEsns_Occ_Freq_lat', 'f8', ('lat',))\n",
    "        SpEsns_Occ_Freq_lat_v[:] = SpEsns_Occ_Freq_lat[:]\n",
    "        SpEsns_Occ_Freq_lat_v.setncattr('units', '%')\n",
    "        SpEsns_Occ_Freq_lat_v.setncattr('description', 'Occ Freq - ds average over all heights')\n",
    "        \n",
    "        SpEs_Occ_Fr_b_dsavg_v = dataset.createVariable('SpEs_Occ_Fr_b_dsavg', 'f8', ('lev_sl', 'lat', 'LT'))\n",
    "        SpEs_Occ_Fr_b_dsavg_v[:] = SpEs_Occ_Fr_b_dsavg[:]\n",
    "        SpEs_Occ_Fr_b_dsavg_v.setncattr('units', '%')\n",
    "        SpEs_Occ_Fr_b_dsavg_v.setncattr('description', 'Occ Freq - ds average at each height')\n",
    "\n",
    "        alt_sl_sh_avg_b_dsavg_v = dataset.createVariable('alt_sl_sh_avg_b_dsavg', 'f8', ('lev_sl', 'lat', 'LT'))\n",
    "        alt_sl_sh_avg_b_dsavg_v[:] = alt_sl_sh_avg_b_dsavg[:]\n",
    "        alt_sl_sh_avg_b_dsavg_v.setncattr('units', 'km')\n",
    "        alt_sl_sh_avg_b_dsavg_v.setncattr('description', 'alt - ds average at each height')\n",
    "        \n",
    "        SpEs_Occ_Fr_b_avg_v = dataset.createVariable('SpEs_Occ_Fr_b_avg', 'f8', ('lev_sl', 'lat', 'LT', 'mth'))\n",
    "        SpEs_Occ_Fr_b_avg_v[:] = SpEs_Occ_Fr_b_avg[:]\n",
    "        SpEs_Occ_Fr_b_avg_v.setncattr('units', '%')\n",
    "        SpEs_Occ_Fr_b_avg_v.setncattr('description', 'Occ Freq - monthly average at each height')\n",
    "\n",
    "        SpEs_Occ_Fr_b_dsavgLT_v = dataset.createVariable('SpEs_Occ_Fr_b_dsavgLT', 'f8', ('lev_sl', 'lat'))\n",
    "        SpEs_Occ_Fr_b_dsavgLT_v[:] = SpEs_Occ_Fr_b_dsavgLT[:]\n",
    "        SpEs_Occ_Fr_b_dsavgLT_v.setncattr('units', '%')\n",
    "        SpEs_Occ_Fr_b_dsavgLT_v.setncattr('description', 'Occ Freq - ds average over all LTs')\n",
    "        \n",
    "        alt_sl_sh_avg_b_dsavgLT_v = dataset.createVariable('alt_sl_sh_avg_b_dsavgLT', 'f8', ('lev_sl', 'lat'))\n",
    "        alt_sl_sh_avg_b_dsavgLT_v[:] = alt_sl_sh_avg_b_dsavgLT[:]\n",
    "        alt_sl_sh_avg_b_dsavgLT_v.setncattr('units', 'km')\n",
    "        alt_sl_sh_avg_b_dsavgLT_v.setncattr('description', 'alt - ds average over all LTs')\n",
    "\n",
    "        SpEs_Occ_Fr_b_avgLT_v = dataset.createVariable('SpEs_Occ_Fr_b_avgLT', 'f8', ('lev_sl', 'lat', 'mth'))\n",
    "        SpEs_Occ_Fr_b_avgLT_v[:] = SpEs_Occ_Fr_b_avgLT[:]\n",
    "        SpEs_Occ_Fr_b_avgLT_v.setncattr('units', '%')\n",
    "        SpEs_Occ_Fr_b_avgLT_v.setncattr('description', 'Occ Freq - monthly average over all LTs')\n",
    "\n",
    "        SpEs_Occ_Fr_bb_5d_dsavg_v = dataset.createVariable('SpEs_Occ_Fr_bb_5d_dsavg', 'f8', ('lev_sl', 'latsl', 'LT'))\n",
    "        SpEs_Occ_Fr_bb_5d_dsavg_v[:] = SpEs_Occ_Fr_bb_5d_dsavg[:]\n",
    "        SpEs_Occ_Fr_bb_5d_dsavg_v.setncattr('units', '%')\n",
    "        SpEs_Occ_Fr_bb_5d_dsavg_v.setncattr('description', 'Occ Freq - ds average at each height in 5deg lat band')\n",
    "\n",
    "        alt_sl_sh_avg_bb_5d_dsavg_v = dataset.createVariable('alt_sl_sh_avg_bb_5d_dsavg', 'f8', ('lev_sl', 'latsl', 'LT'))\n",
    "        alt_sl_sh_avg_bb_5d_dsavg_v[:] = alt_sl_sh_avg_bb_5d_dsavg[:]\n",
    "        alt_sl_sh_avg_bb_5d_dsavg_v.setncattr('units', 'km')\n",
    "        alt_sl_sh_avg_bb_5d_dsavg_v.setncattr('description', 'Alt - ds average lev-LT in 5deg lat band')\n",
    "\n",
    "        SpEsns_Occ_Fr_dsavg_v = dataset.createVariable('SpEsns_Occ_Fr_dsavg', 'f8', ('lev_sl', 'lat', 'lon'))\n",
    "        SpEsns_Occ_Fr_dsavg_v[:] = SpEsns_Occ_Fr_dsavg[:]\n",
    "        SpEsns_Occ_Fr_dsavg_v.setncattr('units', '%')\n",
    "        SpEsns_Occ_Fr_dsavg_v.setncattr('description', 'Occ Freq - ds average at each height')\n",
    " \n",
    "        SpEs_Occ_Freq_llbav_v = dataset.createVariable('SpEs_Occ_Freq_llbav', 'f8', ( 'lat', 'LT'))\n",
    "        SpEs_Occ_Freq_llbav_v[:] = SpEs_Occ_Freq_llbav[:]\n",
    "        SpEs_Occ_Freq_llbav_v.setncattr('units', '%')\n",
    "        SpEs_Occ_Freq_llbav_v.setncattr('description', 'Occ Freq - ds average (lat,LT), alternative way of counting stats over height')\n",
    "\n",
    "        SpEsns_Occ_Freq_llav_v = dataset.createVariable('SpEsns_Occ_Freq_llav', 'f8', ( 'lat', 'lon'))\n",
    "        SpEsns_Occ_Freq_llav_v[:] = SpEsns_Occ_Freq_llav[:]\n",
    "        SpEsns_Occ_Freq_llav_v.setncattr('units', '%')\n",
    "        SpEsns_Occ_Freq_llav_v.setncattr('description', 'Occ Freq - ds average (lat,lon), alternative way of counting stats over height')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # LOCAL TIME\n",
    "        SpEs_v = dataset.createVariable('SpEs', 'f8', ('lev_sl', 'time', 'lat', 'LT_L', 'timesl', 'mth'))\n",
    "        SpEs_v[:] = SpEs[:]\n",
    "        SpEs_v.setncattr('units', '%')\n",
    "        SpEs_v.setncattr('description', 'Metal density (144xLT) where Es layer identified (NaNs elsewhere)')\n",
    "\n",
    "        Mptdens_sh_v = dataset.createVariable('Mptdens_sh', 'f8', ('lev_sl', 'time', 'lat', 'LT_L', 'timesl', 'mth'))\n",
    "        Mptdens_sh_v[:] = Mptdens_sh[:]\n",
    "        Mptdens_sh_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_sh_v.setncattr('description', 'Metal density (144xLT)')\n",
    "\n",
    "        \n",
    "        # LAT-LON\n",
    "        SpEsns_v = dataset.createVariable('SpEsns', 'f8', ('lev_sl', 'time', 'lat', 'lon', 'timesl', 'mth'))\n",
    "        SpEsns_v[:] = SpEsns[:]\n",
    "        SpEsns_v.setncattr('units', '%')\n",
    "        SpEsns_v.setncattr('description', 'Metal density (lon) where Es layer identified (NaNs elsewhere)')\n",
    "\n",
    "        Mptdensns_v = dataset.createVariable('Mptdensns', 'f8', ('lev_sl', 'time', 'lat', 'lon', 'timesl', 'mth'))\n",
    "        Mptdensns_v[:] = Mptdensns[:]\n",
    "        Mptdensns_v.setncattr('units', 'cm-3')\n",
    "        Mptdensns_v.setncattr('description', 'Metal density (lon)')\n",
    "        \n",
    "        Mptdens_nsstd_v = dataset.createVariable('Mptdens_nsstd', 'f8', ('lev_sl', 'lat', 'lon', 'timesl', 'mth'))\n",
    "        Mptdens_nsstd_v[:] = Mptdens_nsstd[:]\n",
    "        Mptdens_nsstd_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_nsstd_v.setncattr('description', 'standard deviation of the M+ layer in each 2wk time slice')\n",
    "            \n",
    "        Mptdens_nsdiff_v = dataset.createVariable('Mptdens_nsdiff', 'f8', ('lev_sl', 'time', 'lat', 'lon', 'timesl', 'mth'))       \n",
    "        Mptdens_nsdiff_v[:] = Mptdens_nsdiff[:]\n",
    "        Mptdens_nsdiff_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_nsdiff_v.setncattr('description', 'Difference between total M+ density and the average M+ layer in each 2wk time slice')\n",
    "          \n",
    "        \n",
    "        Mptdens_nsavg_v = dataset.createVariable('Mptdens_nsavg', 'f8', ('lev_sl', 'lat', 'lon', 'timesl', 'mth'))\n",
    "        Mptdens_nsavg_v[:] = Mptdens_nsavg[:]\n",
    "        Mptdens_nsavg_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_nsavg_v.setncattr('description', 'avg M+ layer for each 2wk time slice')\n",
    "        \n",
    "    \n",
    "        Mptdens_avv1_b_5d_v = dataset.createVariable('Mptdens_avv1_b_5d', 'f8', ('lev_sl', 'latsl', 'timesl', 'mth'))\n",
    "        Mptdens_avv1_b_5d_v[:] = Mptdens_avv1_b_5d[:]\n",
    "        Mptdens_avv1_b_5d_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_avv1_b_5d_v.setncattr('description', 'zonal avg M layer in 5deg lat slices (for each 2wk time slice)')\n",
    "        \n",
    "        Mptdens_std_v = dataset.createVariable('Mptdens_std', 'f8', ('lev_sl', 'lat', 'LT_L', 'timesl', 'mth'))\n",
    "        Mptdens_std_v[:] = Mptdens_std[:]\n",
    "        Mptdens_std_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_std_v.setncattr('description', 'standard deviation of the M+ layer in each 2wk time slice')\n",
    "        \n",
    "        Mptdens_avg_v = dataset.createVariable('Mptdens_avg', 'f8', ('lev_sl', 'lat', 'LT_L', 'timesl', 'mth'))\n",
    "        Mptdens_avg_v[:] = Mptdens_avg[:]\n",
    "        Mptdens_avg_v.setncattr('units', 'cm-3')\n",
    "        Mptdens_avg_v.setncattr('description', 'avg M+ layer for each 2wk time slice')\n",
    "        \n",
    "        \n",
    "        #No of occurences in each grid box in 2wk period (in lon and LT)\n",
    "        SpEs_freq_time_v = dataset.createVariable('SpEs_freq_time', 'f8', ('lev_sl', 'lat', 'LT_L', 'timesl', 'mth'))\n",
    "        SpEs_freq_time_v[:] = SpEs_freq_time[:]\n",
    "        SpEs_freq_time_v.setncattr('units', 'cm-3')\n",
    "        SpEs_freq_time_v.setncattr('description', 'total SpE occurences in 2 week time period (on LT axis (144 long)')\n",
    "        \n",
    "        SpEsns_freq_time_v = dataset.createVariable('SpEsns_freq_time', 'f8', ('lev_sl', 'lat', 'lon', 'timesl', 'mth'))\n",
    "        SpEsns_freq_time_v[:] = SpEsns_freq_time[:]\n",
    "        SpEsns_freq_time_v.setncattr('units', 'cm-3')\n",
    "        SpEsns_freq_time_v.setncattr('description', 'total SpE occurences in 2 week time period (on lon axis)')\n",
    "        \n",
    "        \n",
    "        \n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d521d028-9446-49f0-90f3-d8740bd5b31e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Dimension sizes & other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "955ff881-4fc2-4f0f-914e-92930a7c80a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define various parameters related to the dimension sizes or diff arrays used in the algorithm\n",
    "\n",
    "def setup_parameters():\n",
    "    # Set time parameters - No of time samples to iterate over (2x 2 week periods)\n",
    "    time_it_shape = 2   \n",
    "    time_ind_2wk_min = [0, 336]\n",
    "    time_ind_2wk_max = [335, 671]\n",
    "\n",
    "    # Set time parameters - No of timesteps in one time sample (2 week period)\n",
    "    time_shape = 336\n",
    "    timear = np.arange(0, time_shape)  # 2 week period (hourly data)\n",
    "\n",
    "    # Lon parameters\n",
    "    lon_shape = 144\n",
    "    lonar = np.arange(0, lon_shape)     \n",
    "    \n",
    "    LTshape = 48 #72\n",
    "    it_arr = np.arange(0, LTshape)  # array 0->LTshape   \n",
    "\n",
    "    # Bin midpoints covering whole range\n",
    "    # LTar = np.arange( ((24/LTshape)/2) , 24 , (24/LTshape))  \n",
    "    # LTlong = np.arange( ((24/lon_shape)/2) , 24 , (24/lon_shape)) #0.0833 to 23.9166, x144 inds 10 min bins\n",
    "    \n",
    "    # Using left edge\n",
    "    LTar = np.arange(0, 24, 24/48)  #0-23.5, 48 long\n",
    "    LTlong = np.arange(0, 24, 24/144)   #0-23.833, 144 long\n",
    "    \n",
    "    \n",
    "    # Lat parameters\n",
    "    lat_shape = 96\n",
    "    latar = np.arange(0, lat_shape)\n",
    "\n",
    "    # Lat grid in 1' increments\n",
    "    newlat = np.arange(-89.5, 90.5, 1)\n",
    "    newlat_shape = 180\n",
    "\n",
    "    # Lat grid in 5' slices (each index is centrepoint of slice)\n",
    "    intlat = np.arange(-87.5, 92.5, 5)\n",
    "    intlat_shape = 36\n",
    "    intlat_ar = np.arange(0, intlat_shape)  # array 0->35\n",
    "\n",
    "    \n",
    "    # Average altitudes over the year (km) - geopotential height and geometric altitude, at indices listed:\n",
    "        # geopotential height:\n",
    "        # zavglist41 = 133.23580932617188\n",
    "        # zavglist42 = 128.60214233398438\n",
    "        # zavglist60 = 89.4076919555664\n",
    "        #geometric altitude:\n",
    "        # altavglist41 = 136.07879638671875\n",
    "        # altavglist42 = 131.2488250732422 ***\n",
    "        # altavglist60 = 90.67900848388672 ***\n",
    "    # 90-130km --> To slice lev dim using indices 42 and 60 inclusive and plot on geometric altitude \n",
    "    #90-150km --> #to slice between indices 38 and 60\n",
    "    \n",
    "    # Slice arrays (lev, altitude) between chosen range from above\n",
    "    #90-150km\n",
    "    lev_sl_idx_min = 38 #42      \n",
    "    lev_sl_idx_max = 60      \n",
    "    lev_shape = (lev_sl_idx_max - lev_sl_idx_min) + 1 \n",
    "    levar = np.arange(0, lev_shape)          \n",
    "\n",
    "    # Create an array with offset needed for each UT time step (24h period)\n",
    "    # Offset by 15 degrees lon each time, lon axis is in 2.5 degree intervals\n",
    "    offset = np.arange(0, 24) * 15 / 2.5 \n",
    "    offset = offset.astype(int)\n",
    "    offset = np.tile(offset, 14)  # tile the array for 2 weeks of 1hrly timesteps 2wks * 168timesteps = 336\n",
    "\n",
    "    # Return all the defined arrays as a tuple\n",
    "    return time_it_shape, time_ind_2wk_min, time_ind_2wk_max, time_shape, timear, lon_shape, LTshape, LTlong, lonar, LTar, LTlong, it_arr, lat_shape, latar, newlat, newlat_shape, intlat, intlat_shape, intlat_ar, lev_sl_idx_min, lev_sl_idx_max, lev_shape, levar, offset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04333098-4188-43ea-836c-462d8fbee46b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Main calculations - for SpEs and crit freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8233b271-5942-478a-b288-2acf838e2f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autumn\n",
      "Dataset: Month 09\n",
      "    Array lev = 1.3e-03hPa : 5.4e-06hPa (approx 90km : 142km z3) (approx 91km : 145km alt)\n",
      "      Time slice 1 = 0001-09-01 00:00:00 : 0001-09-14 23:00:00\n",
      "      Time slice 1 = 6.66563105388334 mins\n",
      "      ----------------------------------------\n",
      "      Time slice 2 = 0001-09-15 00:00:00 : 0001-09-28 23:00:00\n",
      "      Time slice 2 = 12.196224708149998 mins\n",
      "      ----------------------------------------\n",
      "         Month 09 Time = 19.422130315916668 mins\n",
      "========================================\n",
      "Dataset: Month 10\n",
      "    Array lev = 1.3e-03hPa : 5.4e-06hPa (approx 90km : 142km z3) (approx 91km : 146km alt)\n",
      "      Time slice 1 = 0001-10-01 00:00:00 : 0001-10-14 23:00:00\n",
      "      Time slice 1 = 7.977353289383329 mins\n",
      "      ----------------------------------------\n",
      "      Time slice 2 = 0001-10-15 00:00:00 : 0001-10-28 23:00:00\n",
      "      Time slice 2 = 7.297817202516671 mins\n",
      "      ----------------------------------------\n",
      "         Month 10 Time = 16.142825825299997 mins\n",
      "========================================\n",
      "Dataset: Month 11\n",
      "    Array lev = 1.3e-03hPa : 5.4e-06hPa (approx 89km : 142km z3) (approx 91km : 146km alt)\n",
      "      Time slice 1 = 0001-11-01 00:00:00 : 0001-11-14 23:00:00\n",
      "      Time slice 1 = 7.010651136133341 mins\n",
      "      ----------------------------------------\n",
      "      Time slice 2 = 0001-11-15 00:00:00 : 0001-11-28 23:00:00\n",
      "      Time slice 2 = 6.929920556816675 mins\n",
      "      ----------------------------------------\n",
      "         Month 11 Time = 14.681148557366669 mins\n",
      "========================================\n",
      "========================================\n",
      "Calculation Time = 50.35072728463333 mins\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: HDF error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 526\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalculation Time = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(time_taken_min) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m mins\u001b[39m\u001b[38;5;124m'\u001b[39m )  \n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m#Save results to nc file\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m save_results(run_name, Monthfolderstr, lev, lev_sl, timear, lat, intlat, lon, LTar, LTlong, time_ar_2wk, ds_months, Zavg_sl, altavg, altavg_sl, times_str_min, times_str_max, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEsns_Occ_Fr_dsavg, SpEs, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_bb_5d_dsavg, Mptdens_avv1_b_5d, Mptdens_std, Mptdens_nsstd, SpEsns_freq_time, SpEs_freq_time, Mptdens_avg, Mptdens_nsdiff, Mptdens_nsavg, SpEs_Occ_Freq_llbav, SpEsns_Occ_Freq_llav, SpEsns_Occ_Freq_lat  )\n",
      "Cell \u001b[0;32mIn[8], line 189\u001b[0m, in \u001b[0;36msave_results\u001b[0;34m(run_name, Monthfolderstr, lev, lev_sl, timear, lat, intlat, lon, LTar, LTlong, time_ar_2wk, ds_months, Zavg_sl, altavg, altavg_sl, times_str_min, times_str_max, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEsns_Occ_Fr_dsavg, SpEs, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_bb_5d_dsavg, Mptdens_avv1_b_5d, Mptdens_std, Mptdens_nsstd, SpEsns_freq_time, SpEs_freq_time, Mptdens_avg, Mptdens_nsdiff, Mptdens_nsavg, SpEs_Occ_Freq_llbav, SpEsns_Occ_Freq_llav, SpEsns_Occ_Freq_lat)\u001b[0m\n\u001b[1;32m    186\u001b[0m SpEsns_v\u001b[38;5;241m.\u001b[39msetncattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetal density (lon) where Es layer identified (NaNs elsewhere)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    188\u001b[0m Mptdensns_v \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcreateVariable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMptdensns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlev_sl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimesl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 189\u001b[0m Mptdensns_v[:] \u001b[38;5;241m=\u001b[39m Mptdensns[:]\n\u001b[1;32m    190\u001b[0m Mptdensns_v\u001b[38;5;241m.\u001b[39msetncattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcm-3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    191\u001b[0m Mptdensns_v\u001b[38;5;241m.\u001b[39msetncattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetal density (lon)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5519\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__setitem__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:5802\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable._put\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: HDF error"
     ]
    }
   ],
   "source": [
    "start_time = time.process_time() \n",
    "\n",
    "\n",
    "#////////////////////////////  Things to check/change before running  ////////////////////////////////////\n",
    "\n",
    "# Critical frequency on/off switch. Turn on (set =1) if wanting to calculate the critical frequency and other related parameters. \n",
    "# Check before using as haven't used in a while and may need updating\n",
    "crit_freq_on = 0   \n",
    "\n",
    "\n",
    "run_name = 'SMin'             #Set to the relevant run name to change input files. Currently working for the runs below:\n",
    "                                    #- Wuhu_IonTr_run - Wuhu's 3 metal run (Fe, Mg and Na). Equivalent to Jianfei_run but done at Leeds. Main dataset for analysis for SpE paper\n",
    "                                    #- Jianfei_run - equivalent to Wuhu_IonTr_run from Wu et al 2021\n",
    "                                    #- Wuhu_IonTr_run_6m - Wuhu's 6 metal run (Fe, Mg, Na, Si, K, Ca) - gives similar results to 3 metal run\n",
    "                                    #- SMin and SMax - solar runs\n",
    "\n",
    "            \n",
    "# Set season/months to use for analysis. Can do one/multiple/all seasons (3 month groups):\n",
    "\n",
    "# ds_months_sets = [['12','01','02'], ['03','04','05'], ['06','07','08'], ['09','10','11']]\n",
    "# Monthstr_sets = [['Dec', 'Jan', 'Feb'], ['Mar', 'Apr', 'May'], ['Jun', 'Jul', 'Aug'], ['Sep', 'Oct', 'Nov']]\n",
    "# season_set = ['winter', 'spring', 'summer', 'autumn']\n",
    "\n",
    "# ds_months_sets = [['12','01','02'], ['06','07','08'], ['09','10','11']]\n",
    "# Monthstr_sets = [['Dec', 'Jan', 'Feb'],  ['Jun', 'Jul', 'Aug'], ['Sep', 'Oct', 'Nov']]\n",
    "# season_set = ['winter', 'summer', 'autumn']\n",
    "\n",
    "# ds_months_sets = [['12','01','02'], ['03','04','05'], ['09','10','11']]\n",
    "# Monthstr_sets = [['Dec', 'Jan', 'Feb'], ['Mar', 'Apr', 'May'], ['Sep', 'Oct', 'Nov']]\n",
    "# season_set = ['winter', 'spring', 'autumn']\n",
    "\n",
    "\n",
    "# ds_months_sets = [ ['03','04','05'], ['12','01','02'] ]\n",
    "# Monthstr_sets = [['Mar', 'Apr', 'May'], ['Dec', 'Jan', 'Feb']  ]\n",
    "# season_set = [ 'spring', 'winter' ]\n",
    "\n",
    "# ds_months_sets = [ ['06','07','08'], ['09','10','11'] ]\n",
    "# Monthstr_sets = [ ['Jun', 'Jul', 'Aug'], ['Sep', 'Oct', 'Nov'] ]\n",
    "# season_set = [ 'summer', 'autumn' ]\n",
    "\n",
    "# ds_months_sets = [ ['03','04','05'], ['06','07','08'] ]\n",
    "# Monthstr_sets = [['Mar', 'Apr', 'May'], ['Jun', 'Jul', 'Aug']  ]\n",
    "# season_set = [ 'spring', 'summer' ]\n",
    "\n",
    "# ds_months_sets = [ ['09','10','11'], ['12','01','02'] ]\n",
    "# Monthstr_sets = [ ['Sep', 'Oct', 'Nov'], ['Dec', 'Jan', 'Feb'] ]\n",
    "# season_set = [ 'autumn', 'winter'  ]\n",
    "\n",
    "# ds_months_sets = [ ['03','04','05'] ]\n",
    "# Monthstr_sets = [ ['Mar', 'Apr', 'May'] ]\n",
    "# season_set = [ 'spring']\n",
    "\n",
    "# ds_months_sets = [['06','07','08']]\n",
    "# Monthstr_sets = [['Jun','Jul','Aug']]\n",
    "# season_set = ['summer']\n",
    "\n",
    "ds_months_sets = [['09','10','11']]\n",
    "Monthstr_sets = [['Sep', 'Oct', 'Nov']]\n",
    "season_set = ['autumn']\n",
    "\n",
    "# ds_months_sets = [['12','01','02']]\n",
    "# Monthstr_sets = [['Dec', 'Jan', 'Feb']]\n",
    "# season_set = ['winter']\n",
    "\n",
    "#////////////////////////////////////////////////  end  /////////////////////////////////////////////////////////\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#/////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "for set_idx in range(len(ds_months_sets)):  #loop through seasons\n",
    "    ds_months = ds_months_sets[set_idx]\n",
    "    ds_months_shape = len(ds_months)\n",
    "    Monthstr = Monthstr_sets[set_idx]\n",
    "    print(season_set[set_idx])\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    time_ar_2wk = np.arange(0,2)\n",
    "    \n",
    "    #Initialising time string arrays used for figure labelling \n",
    "    if ds_months_shape == 1:\n",
    "        times_str_min = np.array( (time_ar_2wk) , dtype=str  ) \n",
    "        times_str_max = np.array( (time_ar_2wk) , dtype=str  ) \n",
    "    elif ds_months_shape ==2:\n",
    "        times_str_min = np.array( (time_ar_2wk,time_ar_2wk) , dtype=str  ) \n",
    "        times_str_max = np.array( (time_ar_2wk,time_ar_2wk) , dtype=str  ) \n",
    "    elif ds_months_shape ==3:   \n",
    "        times_str_min = np.array( (time_ar_2wk,time_ar_2wk,time_ar_2wk) , dtype=str  ) \n",
    "        times_str_max = np.array( (time_ar_2wk,time_ar_2wk,time_ar_2wk) , dtype=str  ) \n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "    #Creating string of relevant months for output file path\n",
    "    Monthfolderstr = Monthstr[0] + '-' + Monthstr[-1]\n",
    "    if ds_months_shape == 1:\n",
    "        Monthfolderstr = Monthstr[0]\n",
    "\n",
    "    #Creating array for iterating through x3 months in each season\n",
    "    ds_months_ar = np.arange(0,ds_months_shape)   #[0,1,2]\n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "\n",
    "    #Call setup_parameters() function\n",
    "    time_it_shape, time_ind_2wk_min, time_ind_2wk_max, time_shape, timear, lon_shape, LTshape, LTlong, lonar, LTar, LTlong, it_arr, lat_shape, latar, newlat, newlat_shape, intlat, intlat_shape, intlat_ar, lev_sl_idx_min, lev_sl_idx_max, lev_shape, levar, offset = setup_parameters()\n",
    "    \n",
    "    #------------------ Variables for selection criteria ----------------------------------------------\n",
    "    sigma_val = 1   #1sigma~68%   (1.5sigma~87%   2sigma~95%)\n",
    "    sigma_val_str = str(sigma_val)\n",
    "\n",
    "    #call define_variables() function\n",
    "    Mptdens_sh, Mptdens_diff, SpEs_sh_nan, Mptdens_avg_b, Mptdens_avv1_b, Mptdens_avv1_b_5d, max_Mptdens_avv1_b_5d, Mptdens_avv1b5d_l, max_Mptdens_avv1b5d_l, Mptdens_avg_bb, Mptdens_avg_bb_5d, Mptdens_avg_bb_5d_avg, Mptdens_avg_bb_5d_avglev, Mptdens_avg_bb_5d_dsavg, Mptdens_avg_bb_5d_dsavglev, edens_sh, SpEs_e, maxSpEs__e, maxSpEs_e, foEs__m, foEs_m, foEs_m_av, foEs_m_av_mth, foEs_m_av_ds, SpEs, SpEs_freq, SpEs_freq_time, SpEs_Occ_Freq, SpEs_Occ_Fr_b, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avgLT, SpEs_Occ_Fr_b_dsavgLT, SpEs_Occ_Fr_bb, SpEs_Occ_Fr_bb_5d, SpEs_Occ_Fr_bb_5d_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEs_Occ_Fr_bb_5d_dsavglev, Mptdensns, Mptdens_nsavg, Mptdens_nsstd, Mptdens_nsdiff, Mptdens_nsavv1_b, Mptdens_nsavv1_b_5d, max_Mptdens_nsavv1_b_5d, Mptdens_nsavv1b5d_l, max_Mptdens_nsavv1b5d_l, edensns, SpEs_nse, maxSpEs__nse, maxSpEs_nse, foEsns__m, foEsns_m, foEsns_m_av, foEsns_m_av_mth, foEsns_m_av_ds, SpEsns, SpEsns_freq_bool, SpEsns_freq, SpEsns_freq_time, SpEsns_Occ_Freq, SpEsns_Occ_Fr_avg, SpEsns_Occ_Fr_dsavg, altavg, altavg_sl, alt_sl_avg, alt_sl_aavg, alt_sl_aaavg, alt_sl_sh, alt_sl_sh_avg, alt_sl_sh_avg_b, alt_sl_sh_avg_b_avg, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_b_avgLT, alt_sl_sh_avg_bb_5d, alt_sl_sh_avg_bb_5d_avg, alt_sl_sh_avg_bb_5d_dsavg, alt_sl_sh_avg_bb ,SpEs_freq_altsum, SpEs_freq_altsum_time, SpEs_Occ_Freq_ll, SpEs_Occ_Freq_llb, SpEs_Occ_Freq_llba, SpEs_Occ_Freq_llbav, SpEsns_freq_altsum, SpEsns_freq_altsum_time, SpEsns_Occ_Freq_ll, SpEsns_Occ_Freq_lla, SpEsns_Occ_Freq_llav  = define_variables(lev_shape, time_shape, lat_shape, lon_shape, LTshape, time_it_shape, ds_months_shape, newlat_shape, intlat_shape, crit_freq_on)\n",
    " \n",
    "    #--------------------------------------------------------------------------------------------------\n",
    "\n",
    "    for ids in ds_months_ar:  #loop through months in season\n",
    "        #===================================================================================================\n",
    "        loop_start_time = time.process_time()   #calculates timing for terminal output\n",
    "        #===================================================================================================\n",
    "        #Define file paths for data source and open dataset\n",
    "        if run_name=='Jianfei_run':\n",
    "            file1name =f'Nc_Files/Jianfei_WACCMX_files/waccmx_Fe_Fep_{ds_months[ids]}.nc'\n",
    "            ds = xr.open_dataset(file1name)\n",
    "        elif run_name=='Wuhu_IonTr_run':\n",
    "            file1name=f'Nc_Files/ACP_CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_iontransport/ACP_CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_iontransport.cam.h2.0001-{ds_months[ids]}-*.nc'\n",
    "            ds = xr.open_mfdataset(file1name)\n",
    "        elif run_name=='Wuhu_IonTr_run_6m':\n",
    "            file1name=f'Nc_Files/CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_Si_Ca_K_iontransport/CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_Si_Ca_K_iontransport.cam.h2.0001-{ds_months[ids]}-*.nc' \n",
    "            ds = xr.open_mfdataset(file1name)\n",
    "        elif run_name=='SMax':\n",
    "            file1name=f'Nc_Files/SMax_3M_FX2000_f19_f19mg16/SMax_3M_FX2000_f19f19mg16.cam.h1.0001-{ds_months[ids]}-*.nc'\n",
    "            ds = xr.open_mfdataset(file1name)\n",
    "        elif run_name=='SMin':\n",
    "            file1name=f'Nc_Files/SMin_3M_FX2000_f19_f19mg16/SMin_3M_FX2000_f19f19mg16.cam.h1.0001-{ds_months[ids]}-*.nc'\n",
    "            ds = xr.open_mfdataset(file1name)\n",
    "        #===================================================================================================\n",
    "        #Define dimension variables\n",
    "        print(f'Dataset: Month {str(ds_months[ids])}') \n",
    "\n",
    "        timee = ds.variables['time']\n",
    "        start_cftime_date = f'0001-{str(ds_months[ids])}-01'\n",
    "        times = xr.cftime_range(start=start_cftime_date, periods=672, freq=\"1H\", calendar=\"noleap\")    \n",
    "\n",
    "        lon = ds.variables['lon']\n",
    "        lat = ds.variables['lat']\n",
    "        lev = ds.variables['lev']\n",
    "        dst = ds.transpose(\"lev\", ...)\n",
    "        #===================================================================================================\n",
    "        #Define more variables that may or may not be from a different file depending ont the run\n",
    "        if run_name=='Jianfei_run':\n",
    "            file2name='Nc_Files/Jianfei_WACCMX_files/waccmx_Z3_T_e_' + ds_months[ids] + '.nc' \n",
    "            ds2 = xr.open_dataset(file2name) \n",
    "            ds2t = ds2.transpose(\"lev\", ...)\n",
    "            temp = ds2t.variables['T']\n",
    "            geopH = ds2t.variables['Z3'] / 1000 #m-> km\n",
    "            if crit_freq_on==1:\n",
    "                elect = ds2t.variables['e']\n",
    "        else:\n",
    "            temp = dst.variables['T']\n",
    "            elect = dst.variables['e']\n",
    "            geopH = dst.variables['Z3'] / 1000 #m-> km    #(126, 744, 96, 144)\n",
    "\n",
    "        Fept = dst.variables['Fep']\n",
    "        Mgpt = dst.variables['Mgp']\n",
    "        Napt = dst.variables['Nap']\n",
    "        \n",
    "        Zavg = geopH.mean(('time','lat', 'lon'))   #Global average of geopotential height (126)\n",
    "\n",
    "        #Convert geopotential height to geometric altitude\n",
    "        Re = 6378 #km\n",
    "        alt = (geopH*Re)/(Re-geopH)\n",
    "        altavg[:,ids] = alt.mean(('time','lat', 'lon')) #global average\n",
    "\n",
    "        #===================================================================================================\n",
    "\n",
    "        # Slice arrays (lev & alt) between chosen geometric altitude range & print\n",
    "        lev_sl = lev[lev_sl_idx_min:lev_sl_idx_max+1]\n",
    "        Zavg_sl = Zavg[lev_sl_idx_min:lev_sl_idx_max+1] \n",
    "        altavg_sl[:,ids] = altavg[lev_sl_idx_min:lev_sl_idx_max+1,ids]\n",
    "        \n",
    "        alt_sl = alt[lev_sl_idx_min:lev_sl_idx_max+1,:,:,:]    \n",
    "\n",
    "        print(f'    Array lev = {str(\"%.1e\" % lev[lev_sl_idx_max])}hPa : {str(\"%.1e\" % lev[lev_sl_idx_min])}hPa'\n",
    "                   + f' (approx {str(\"%.0f\" % Zavg[lev_sl_idx_max])}km : {str(\"%.0f\" % Zavg[lev_sl_idx_min])}km z3)'   \n",
    "                   + f' (approx {str(\"%.0f\" % altavg[lev_sl_idx_max,ids])}km : {str(\"%.0f\" % altavg[lev_sl_idx_min,ids])}km alt)'   )\n",
    "\n",
    "\n",
    "        for it2 in time_ar_2wk:  #loop through two two-week periods each month\n",
    "            #===================================================================================================\n",
    "            loop1_start_time = time.process_time()   #loop timing for printout\n",
    "            #===================================================================================================\n",
    "\n",
    "            #Select time indices for current loop iteration\n",
    "            times_idx_min = time_ind_2wk_min[it2]\n",
    "            times_idx_max = time_ind_2wk_max[it2]\n",
    "\n",
    "            # Generate time strings for figure labelling\n",
    "            if ds_months_shape>1:\n",
    "                times_str_min[ids][it2] = str( times[times_idx_min] ) #~~#\n",
    "                times_str_max[ids][it2] = str( times[times_idx_max] ) #~~#\n",
    "                print( '      Time slice ' + str(it2+1) + ' = ' +times_str_min[ids][it2] + ' : ' + times_str_max[ids][it2] ) \n",
    "            else:\n",
    "                times_str_min[it2] = str( times[times_idx_min] ) #~~#\n",
    "                times_str_max[it2] = str( times[times_idx_max] ) #~~#\n",
    "                print( '      Time slice ' + str(it2+1) + ' = ' + str( times_str_min[it2] ) + ' : ' + str( times_str_max[it2] ) ) \n",
    "            #===================================================================================================\n",
    "\n",
    "            # Slice metal arrays by chosen alt range and time range \n",
    "            tempe = temp[lev_sl_idx_min:lev_sl_idx_max+1,times_idx_min:times_idx_max+1,:,:]\n",
    "            \n",
    "            # Mp_t = Mpt[lev_sl_idx_min:lev_sl_idx_max+1,times_idx_min:times_idx_max+1,:,:]\n",
    "            Fep_t = Fept[lev_sl_idx_min:lev_sl_idx_max+1,times_idx_min:times_idx_max+1,:,:]\n",
    "            Mgp_t = Mgpt[lev_sl_idx_min:lev_sl_idx_max+1,times_idx_min:times_idx_max+1,:,:]\n",
    "            Nap_t = Napt[lev_sl_idx_min:lev_sl_idx_max+1,times_idx_min:times_idx_max+1,:,:]\n",
    "\n",
    "            if crit_freq_on==1:\n",
    "                elec = elect[lev_sl_idx_min:lev_sl_idx_max+1,times_idx_min:times_idx_max+1,:,:]\n",
    "            #===================================================================================================\n",
    "\n",
    "            # VMR to number density calculation\n",
    "            Feptdens = ( Fep_t * 1e-6 * 100 * lev_sl ) / (1.380503e-23 * tempe)\n",
    "            Mgptdens = ( Mgp_t * 1e-6 * 100 * lev_sl ) / (1.380503e-23 * tempe)\n",
    "            Naptdens = ( Nap_t * 1e-6 * 100 * lev_sl ) / (1.380503e-23 * tempe)\n",
    "            \n",
    "            Mptdens = Feptdens + (2 * Mgptdens ) + Naptdens    #Approx total metal density            \n",
    "            \n",
    "            if crit_freq_on==1:\n",
    "                edens = ( elec * 1e-6 * 100 * lev_sl ) / (1.380503e-23 * tempe)\n",
    "\n",
    "\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "            #==================For Lat-LT PLOTS. Shifting Mptdens from lon to local time========================\n",
    "            #===================================================================================================\n",
    "            #Iterate over timear (2wk period, hrly data), offset density at each UT by 15 degrees lon\n",
    "            for it in timear: \n",
    "                Mptdens_sh[:,it,:,:,it2,ids] = np.roll(Mptdens[:,it,:,:], offset[it] , axis=2)\n",
    "                alt_sl_sh[:,it,:,:,it2,ids] = np.roll(alt_sl[:,it,:,:], offset[it] , axis=2)     #(19,744,96,144,2,3)\n",
    "                \n",
    "                if crit_freq_on==1:\n",
    "                    edens_sh[:,it,:,:,it2,ids] = np.roll(edens[:,it,:,:], offset[it] , axis=2)\n",
    "            #===================================================================================================\n",
    "            # Calculate average along time axis for 2wk sample\n",
    "            alt_sl_sh_avg[:,:,:,it2,ids] = np.mean(alt_sl_sh[:,:,:,:,it2,ids],  axis=1)     #(19,744,96,144,2,3)->(19,96,144,2,3)\n",
    "            alt_sl_avg[:,:,:,it2,ids] = np.mean(alt_sl,  axis=1)  #average of non-shifted (lat,lon) altitude  #(19,744,96,144)->(19,96,144,2,3)\n",
    "            #===================================================================================================\n",
    "            # Calculate average of offset densities along time axis for 2wk sample\n",
    "            Mptdens_avg = np.mean(Mptdens_sh,  axis=1) #-> (25, 96, 144, 2, 3)\n",
    "\n",
    "            # Calculate std dev of offset densities along time axis\n",
    "            Mptdens_std = np.std(Mptdens_sh, axis=1) #-> (25, 96, 144, 2, 3)\n",
    "\n",
    "            # Calculate difference between density from model output and the average density       \n",
    "            for it in timear:\n",
    "                Mptdens_diff[:,it,:,:,it2,ids] = Mptdens_sh[:,it,:,:,it2,ids] - Mptdens_avg[:,:,:,it2,ids]      \n",
    "            #===================================================================================================\n",
    "            #Work out zonal avg M layer in 5' lat slices (for each 2wk time slice) & max over lev dim\n",
    "            Mptdens_avv1 = np.mean(Mptdens_avg, axis=2) #avg Mptdens_avg over lon dim -> (25, 96, 2, 3). (equiv to Mptdens avg'd over timestep & lon dims)\n",
    "            \n",
    "            for ilev in levar: #interpolate onto newlat grid 1' spacing (180 long)\n",
    "                Mptdens_avv1_b[ilev,:,it2,ids] = np.interp( newlat, lat, Mptdens_avv1[ilev,:,it2,ids] )  \n",
    "\n",
    "                for iintlat in intlat_ar: #average into 5' lat slices\n",
    "                    Mptdens_avv1_b_5d[ilev,iintlat,it2,ids] = np.mean( Mptdens_avv1_b[ilev,(iintlat*5):((iintlat*5)+5),it2,ids] ) #'GLOBAL' AVG AT HEIGHT X IN 5' SLICES (25, 36, 2, 1)\n",
    "\n",
    "            max_Mptdens_avv1_b_5d[:,it2,ids] = np.amax(Mptdens_avv1_b_5d[:,:,it2,ids], axis=0) # find max over lev dim  #PEAK OF 'GLOBAL' AVG M LAYER IN 5' SLICES (36, 2, 1)\n",
    "            #===================================================================================================\n",
    "            #Assigns correct lat slice (dim 36 long) to variable with normal lat axis (96 long) so this can be used in criteria below. Probably a function to do this much better/in a diff way but I wrote it a long time ago....\n",
    "            Z = 0\n",
    "            X = -90\n",
    "            Y = -85\n",
    "            for ilat in latar:\n",
    "                if lat[ilat] > Y :\n",
    "                    X = X + 5\n",
    "                    Y = Y + 5 \n",
    "                    Z = Z + 1\n",
    "                if (lat[ilat]>=X) & (lat[ilat]<=Y) :\n",
    "                    max_Mptdens_avv1b5d_l[ ilat ,it2,ids] = max_Mptdens_avv1_b_5d[ Z ,it2,ids] #peak of layer over lev dim\n",
    "                    Mptdens_avv1b5d_l[:, ilat ,it2,ids] = Mptdens_avv1_b_5d[:, Z ,it2,ids]  #metal layer as fct of height       \n",
    "            #===================================================================================================\n",
    "            # CRITERIA & Es Identifiation Calculations (LT)\n",
    "            #===================================================================================================\n",
    "            # Where criteria set are met, set SpEs array to Mptdens_sh (total metal density), otherwise set to NaN\n",
    "            #Criteria are: ( Diff > 0.25x sigma )  &  ( Mpt > 2x glb average at height x in 5' slice)  &  ( Mpt > 1x glb avg layer peak in 5' slice)\n",
    "            \n",
    "            SpEs[:,:,:,:,it2,ids] = np.where( ( Mptdens_diff[:,:,:,:,it2,ids]>( 0.25 * sigma_val*Mptdens_std[:,None,:,:,it2,ids]) ) & \n",
    "                                                ( Mptdens_sh[:,:,:,:,it2,ids] > ( 2 * Mptdens_avv1b5d_l[:,None,:,None,it2,ids] ) ) &    \n",
    "                                               ( Mptdens_sh[:,:,:,:,it2,ids] > ( 1 * max_Mptdens_avv1b5d_l[None,None,:,None,it2,ids] ) )    , Mptdens_sh[:,:,:,:,it2,ids] , SpEs_sh_nan[:,:,:,:,it2,ids] )\n",
    "            # \n",
    "                \n",
    "            if crit_freq_on==1: \n",
    "                SpEs_e[:,:,:,:,it2,ids] = np.where( SpEs[:,:,:,:,it2,ids]==Mptdens_sh[:,:,:,:,it2,ids], edens_sh[:,:,:,:,it2,ids] , SpEs_sh_nan[:,:,:,:,it2,ids] ) \n",
    "\n",
    "            \n",
    "            #===================================================================================================\n",
    "            if crit_freq_on==1:    \n",
    "                #Calculate critical ionosonde frequency    \n",
    "                maxSpEs__e[:,:,:,it2,ids] = np.nanmax(SpEs_e[:,:,:,:,it2,ids], axis=0)  #find max over lev dim\n",
    "                maxSpEs_e[:,:,:,it2,ids] =maxSpEs__e[:,:,:,it2,ids] * 1e6   #cm-3 -> m-3\n",
    "\n",
    "                foEs__m[:,:,:,it2,ids] = 8.98 * np.sqrt(maxSpEs_e[:,:,:,it2,ids])\n",
    "                foEs_m[:,:,:,it2,ids] = foEs__m[:,:,:,it2,ids] / 1e6    #Hz -> MHz\n",
    "\n",
    "                foEs_m_av[:,:,it2,ids] = np.nanmean( foEs_m[:,:,:,it2,ids], axis=0 ) #avg over lev dim\n",
    "\n",
    "            #===================================================================================================\n",
    "            #Calculate Occurence freq\n",
    "            SpEs_freq[:,:,:,:,it2,ids] = np.isfinite(SpEs[:,:,:,:,it2,ids]) *1.  #Where SpEs is a number, set to True, otherwise set to False, then convert True/False to 1/0s\n",
    "            SpEs_freq_time[:,:,:,it2,ids] = np.sum(SpEs_freq[:,:,:,:,it2,ids], axis=1) #Sum over Time dim to give SpEs_freq_time (total occurences in 2 week time period) -> (19,96,144,2,3)\n",
    "            SpEs_Occ_Freq[:,:,:,it2,ids] = ( SpEs_freq_time[:,:,:,it2,ids] / time_shape ) *100.    #Divide by number of timesteps (336) to give occurence freq (%)  # (19,96,144,2,3)\n",
    "            \n",
    "            #interpolate from x144 inds to xLTshape\n",
    "            for ilev in levar:\n",
    "                for ilat in latar:\n",
    "                    SpEs_Occ_Fr_b[ilev,ilat,:,it2,ids] = np.interp(LTar, LTlong, SpEs_Occ_Freq[ilev,ilat,:,it2,ids])\n",
    "                    Mptdens_avg_b[ilev,ilat,:,it2,ids] = np.interp(LTar, LTlong, Mptdens_avg[ilev,ilat,:,it2,ids])  \n",
    "                    alt_sl_sh_avg_b[ilev,ilat,:,it2,ids] = np.interp(LTar, LTlong, alt_sl_sh_avg[ilev,ilat,:,it2,ids])\n",
    "                    \n",
    "            #- - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "            # For alt-LT plots (want to plot an average for a 5' lat slice)\n",
    "            # Bin into 1' lat bins instead of 1.89' (180 long) then avg in 5' slices   \n",
    "            for ilev in levar:\n",
    "                for iit_arr in it_arr: #interpolate onto newlat grid 1' spacing (180 long) (was 1.89')\n",
    "                    SpEs_Occ_Fr_bb[ilev,:,iit_arr,it2,ids] = np.interp( newlat, lat, SpEs_Occ_Fr_b[ilev,:,iit_arr,it2,ids] )  \n",
    "                    Mptdens_avg_bb[ilev,:,iit_arr,it2,ids] = np.interp( newlat, lat, Mptdens_avg_b[ilev,:,iit_arr,it2,ids] )  \n",
    "                    alt_sl_sh_avg_bb[ilev,:,iit_arr,it2,ids] = np.interp( newlat, lat, alt_sl_sh_avg_b[ilev,:,iit_arr,it2,ids] )  \n",
    "\n",
    "                    for iintlat in intlat_ar: #avg interpolated array into 5' slices\n",
    "                        SpEs_Occ_Fr_bb_5d[ilev,iintlat,iit_arr,it2,ids] = np.mean(   SpEs_Occ_Fr_bb[ilev,(iintlat*5):((iintlat*5)+5),iit_arr,it2,ids] )   #average in 5' slices\n",
    "                        Mptdens_avg_bb_5d[ilev,iintlat,iit_arr,it2,ids] = np.mean(   Mptdens_avg_bb[ilev,(iintlat*5):((iintlat*5)+5),iit_arr,it2,ids] )   #average in 5' slices\n",
    "                        alt_sl_sh_avg_bb_5d[ilev,iintlat,iit_arr,it2,ids] = np.mean(   alt_sl_sh_avg_bb[ilev,(iintlat*5):((iintlat*5)+5),iit_arr,it2,ids] )   #average in 5' slices\n",
    "\n",
    "            #=================================================================================================== \n",
    "            #Calculate Occurrence freq over lat-LT by summing over alt dim (for lat-LT plots)\n",
    "            SpEs_freq_altsum[:,:,:,it2,ids] = np.sum(SpEs_freq[:,:,:,:,it2,ids],axis=0) #sum over alt dim\n",
    "            SpEs_freq_altsum_time[:,:,it2,ids] = np.sum(SpEs_freq_altsum[:,:,:,it2,ids],axis=0)  #sum over time dim\n",
    "            SpEs_Occ_Freq_ll[:,:,it2,ids] = SpEs_freq_altsum_time[:,:,it2,ids] / (time_shape*lev_shape) * 100.\n",
    "            #- - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "            #interpolate from x144 LT inds to xLTshape\n",
    "            for ilat in latar:\n",
    "                SpEs_Occ_Freq_llb[ilat,:,it2,ids] = np.interp(LTar, LTlong, SpEs_Occ_Freq_ll[ilat,:,it2,ids]) \n",
    "            \n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "\n",
    "\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "            #====================For Lat-LON PLOTS. Repeat of above usng non-shifted Mptdens====================\n",
    "            #===================================================================================================\n",
    "\n",
    "            Mptdensns[:,:,:,:,it2,ids] = Mptdens[:,:,:,:] #(19, 336, 96, 144, 2, 3)\n",
    "            if crit_freq_on==1:\n",
    "                edensns[:,:,:,:,it2,ids] = edens[:,:,:,:] #(19, 336, 96, 144, 2, 3)\n",
    "\n",
    "            # Calculate average of densities along time axis for 2wk sample\n",
    "            Mptdens_nsavg[:,:,:,it2,ids] = np.mean(Mptdensns[:,:,:,:,it2,ids],  axis=1) #-> (19, 96, 144, 2, 3)\n",
    "\n",
    "            # Calculate std dev of densities along time axis\n",
    "            Mptdens_nsstd[:,:,:,it2,ids] = np.std(Mptdensns[:,:,:,:,it2,ids], axis=1) #-> (19, 96, 144, 2, 3)\n",
    "\n",
    "            # Calculate difference between density from model output and the average density     \n",
    "            for it in timear:\n",
    "                Mptdens_nsdiff[:,it,:,:,it2,ids] = Mptdensns[:,it,:,:,it2,ids] - Mptdens_nsavg[:,:,:,it2,ids]      \n",
    "            #===================================================================================================\n",
    "            #Work out zonal avg M layer in 5' lat slices (for each 2wk time slice) & max over lev dim\n",
    "            Mptdens_nsavv1 = np.mean(Mptdens_nsavg, axis=2) #avg Mptdens_avg over lon dim -> (19, 96, 2, 3). (equiv to Mptdens avg'd over timestep & lon dims)\n",
    "            #- - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "            for ilev in levar: #interpolate onto newlat grid 1' spacing (180 long)\n",
    "                Mptdens_nsavv1_b[ilev,:,it2,ids] = np.interp( newlat, lat, Mptdens_nsavv1[ilev,:,it2,ids] )  \n",
    "\n",
    "                for iintlat in intlat_ar: #average into 5' lat slices\n",
    "                    Mptdens_nsavv1_b_5d[ilev,iintlat,it2,ids] = np.mean( Mptdens_nsavv1_b[ilev,(iintlat*5):((iintlat*5)+5),it2,ids] ) #'GLOBAL' AVG AT HEIGHT X IN 5' SLICES (19, 36, 2, 1)\n",
    "\n",
    "            max_Mptdens_nsavv1_b_5d[:,it2,ids] = np.amax(Mptdens_nsavv1_b_5d[:,:,it2,ids], axis=0) # find max over lev dim  #PEAK OF 'GLOBAL' AVG M LAYER IN 5' SLICES (36, 2, 1)\n",
    "            #===================================================================================================\n",
    "            #Assigns correct lat slice (dim 36 long) to variable with normal lat axis (96 long) so this can be used in criteria below\n",
    "            Z = 0\n",
    "            X = -90\n",
    "            Y = -85\n",
    "            for ilat in latar:\n",
    "                if lat[ilat] > Y :\n",
    "                    X = X + 5\n",
    "                    Y = Y + 5 \n",
    "                    Z = Z + 1\n",
    "                if (lat[ilat]>=X) & (lat[ilat]<=Y) :\n",
    "                    max_Mptdens_nsavv1b5d_l[ ilat ,it2,ids] = max_Mptdens_nsavv1_b_5d[ Z ,it2,ids] #peak of layer over lev dim\n",
    "                    Mptdens_nsavv1b5d_l[:, ilat ,it2,ids] = Mptdens_nsavv1_b_5d[:, Z ,it2,ids]  #metal layer as fct of height  \n",
    "                    \n",
    "            #===================================================================================================\n",
    "            # CRITERIA & Es Identifiation Calculations (Lon)\n",
    "            #===================================================================================================\n",
    "            # Where criteria set are met, set SpEs to Mptdens, otherwise set to NaN\n",
    "            #Criteria are: ( Diff > 0.25x sigma )  &  ( Mpt > 2x glb average at height x in 5' slice)  &  ( Mpt > 1x glb avg layer peak in 5' slice)   \n",
    "\n",
    "            SpEsns[:,:,:,:,it2,ids] = np.where( ( Mptdens_nsdiff[:,:,:,:,it2,ids]>( 0.25 * sigma_val*Mptdens_nsstd[:,None,:,:,it2,ids]) ) &  \n",
    "                                                   ( Mptdensns[:,:,:,:,it2,ids] > ( 2 * Mptdens_nsavv1b5d_l[:,None,:,None,it2,ids] ) ) &  \n",
    "                                                 ( Mptdensns[:,:,:,:,it2,ids] > ( 1 * max_Mptdens_nsavv1b5d_l[None,None,:,None,it2,ids] ) ) , Mptdensns[:,:,:,:,it2,ids] , SpEs_sh_nan[:,:,:,:,it2,ids] )\n",
    "            #\n",
    "            \n",
    "            if crit_freq_on==1: \n",
    "                SpEs_nse[:,:,:,:,it2,ids] = np.where( SpEsns[:,:,:,:,it2,ids]==Mptdensns[:,:,:,:,it2,ids], edensns[:,:,:,:,it2,ids] , SpEs_sh_nan[:,:,:,:,it2,ids] ) \n",
    "\n",
    "            #===================================================================================================\n",
    "            if crit_freq_on==1:    \n",
    "                #Calculate critical ionosonde frequency    \n",
    "                maxSpEs__nse[:,:,:,it2,ids] = np.nanmax(SpEs_nse[:,:,:,:,it2,ids], axis=0)  #find max over lev dim\n",
    "                maxSpEs_nse[:,:,:,it2,ids] =maxSpEs__nse[:,:,:,it2,ids] * 1e6   #cm-3 -> m-3\n",
    "\n",
    "                foEsns__m[:,:,:,it2,ids] = 8.98 * np.sqrt(maxSpEs_nse[:,:,:,it2,ids])\n",
    "                foEsns_m[:,:,:,it2,ids] = foEsns__m[:,:,:,it2,ids] / 1e6    #Hz -> MHz\n",
    "\n",
    "                foEsns_m_av[:,:,it2,ids] = np.nanmean( foEsns_m[:,:,:,it2,ids], axis=0 ) #avg over timestep dim\n",
    "\n",
    "            #===================================================================================================\n",
    "            #Calculate Occurence freq\n",
    "\n",
    "            SpEsns_freq[:,:,:,:,it2,ids] = np.isfinite(SpEsns[:,:,:,:,it2,ids]) *1. #Convert True/False to 1/0s -> (19,336,96,144,2,3)\n",
    "            SpEsns_freq_time[:,:,:,it2,ids] = np.sum(SpEsns_freq[:,:,:,:,it2,ids], axis=1) #Sum over Time dim to give SpEs_freq_time (total occurences in 2 week time period) -> (19,96,144,2,3)\n",
    "            SpEsns_Occ_Freq[:,:,:,it2,ids] = ( SpEsns_freq_time[:,:,:,it2,ids] / time_shape ) *100.    #Divide by number of timesteps (336) to give occurence freq (%)  # (19,96,144,2,3)\n",
    "            \n",
    "            SpEsns_freq_altsum[:,:,:,it2,ids] = np.sum(SpEsns_freq[:,:,:,:,it2,ids],axis=0) #sum over alt dim\n",
    "            SpEsns_freq_altsum_time[:,:,it2,ids] = np.sum(SpEsns_freq_altsum[:,:,:,it2,ids],axis=0)  #sum over time dim\n",
    "            SpEsns_Occ_Freq_ll[:,:,it2,ids] = SpEsns_freq_altsum_time[:,:,it2,ids] / (time_shape*lev_shape) * 100.\n",
    "            \n",
    "            \n",
    "            #===================================================================================================\n",
    "#////////////////////////////////////////////////////////////////////////////////////////////////////////////////////   \n",
    "\n",
    "\n",
    "            #===================================================================================================\n",
    "            #Calculate loop timings for printout\n",
    "            loop1_end_time = time.process_time()\n",
    "            loop1_time_taken = loop1_end_time - loop1_start_time\n",
    "            loop1_time_taken_min = loop1_time_taken / 60.\n",
    "\n",
    "            print('      Time slice ' + str(it2+1) + ' = ' + str(loop1_time_taken_min) + ' mins' ) \n",
    "            print('      ----------------------------------------')\n",
    "            #===================================================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #--- Out of it2 loop (2wk time periods), still in ds loop (month) --- Calculating monthly averages for relevant variables, including altitude with same dims as each output array\n",
    " \n",
    "        ###__SpEs_Occ_Fr__###\n",
    "    \n",
    "        #Lat,LT at specific heights, monthly avg -> (lev,lat,LT,ids)\n",
    "        #(Using SpEs_Occ_Fr_b averaged in 0.5h LT slices but not into 5' lat slices)\n",
    "        SpEs_Occ_Fr_b_avg[:,:,:,ids] = np.mean(SpEs_Occ_Fr_b[:,:,:,:,ids],  axis=3) #avg over it2 dim (avg both 2wk periods)  => Monthly avg (19, 96, 48, 3)\n",
    "        alt_sl_sh_avg_b_avg[:,:,:,ids] = np.mean(alt_sl_sh_avg_b[:,:,:,:,ids],  axis=3)  #(19,96,48,2,3)->(19,96,48,3)\n",
    "        \n",
    "        #LT avg ->(lev,lat,ids)   \n",
    "        SpEs_Occ_Fr_b_avgLT[:,:,ids] = np.mean(SpEs_Occ_Fr_b_avg[:,:,:,ids],  axis=2)  #avg over LT dim =>  #alt-lat monthly avg (19, 96, 3) \n",
    "        alt_sl_sh_avg_b_avgLT[:,:,ids] = np.mean(alt_sl_sh_avg_b_avg[:,:,:,ids],  axis=2)  #avg over LT dim =>  #alt-lat monthly avg (19, 96, 3) \n",
    "\n",
    "        #5' lat bins ->(lev,5'lat,LT,ids) \n",
    "        SpEs_Occ_Fr_bb_5d_avg[:,:,:,ids] = np.mean(SpEs_Occ_Fr_bb_5d[:,:,:,:,ids],  axis=3) #avg over it2 dim (avg both 2wk periods) => Monthly avg   ->(19, 36, 48, 3)\n",
    "        alt_sl_sh_avg_bb_5d_avg[:,:,:,ids] = np.mean(alt_sl_sh_avg_bb_5d[:,:,:,:,ids],  axis=3) \n",
    "\n",
    "        #Lat-Lon ->(lev,lat,lon,ids)\n",
    "        SpEsns_Occ_Fr_avg[:,:,:,ids] = np.mean(SpEsns_Occ_Freq[:,:,:,:,ids],  axis=3) #avg over it2 dim (avg both 2wk periods)  => Monthly avg (19,96,144,3)\n",
    "        alt_sl_aavg[:,:,:,ids] = np.mean(alt_sl_avg[:,:,:,:,ids],  axis=3)     #lon axis   #(19,96,144,2,3)->(19,96,144,3)\n",
    "\n",
    "        SpEs_Occ_Freq_llba[:,:,ids] = np.mean(SpEs_Occ_Freq_llb[:,:,:,ids],  axis=2)  #average over it2 dim \n",
    "        SpEsns_Occ_Freq_lla[:,:,ids] = np.mean(SpEsns_Occ_Freq_ll[:,:,:,ids],  axis=2)\n",
    "        \n",
    "        \n",
    "        ###__FoEs_Monthly_avg___###\n",
    "        if crit_freq_on==1:\n",
    "            foEs_m_av_mth[:,:,ids] = np.nanmean( foEs_m_av[:,:,:,ids], axis=2 )\n",
    "            foEsns_m_av_mth[:,:,ids] = np.nanmean( foEsns_m_av[:,:,:,ids], axis=2 )\n",
    "\n",
    "\n",
    "\n",
    "        #===================================================================================================\n",
    "        #Loop timings for printout\n",
    "        loop_end_time = time.process_time()\n",
    "        loop_time_taken = loop_end_time - loop_start_time\n",
    "        loop_time_taken_min = loop_time_taken / 60.\n",
    "\n",
    "        print('         Month ' + str(ds_months[ids]) + ' Time = ' + str(loop_time_taken_min) + ' mins' )  \n",
    "        print('========================================')\n",
    "        #===================================================================================================\n",
    "\n",
    "\n",
    "\n",
    "    #--- Out of it2 loop (2wk time periods) AND ds loop (month) ---   \n",
    "\n",
    "    ###__SpEs_Occ_Fr__###\n",
    "    \n",
    "    #(lev,lat,LT), Lat,LT at specific heights \n",
    "    SpEs_Occ_Fr_b_dsavg[:,:,:] = np.mean(SpEs_Occ_Fr_b_avg[:,:,:,:],  axis=3) #avg over ids dim (avg all months)   =Whole Dataset avg   ->(19, 96, 48)\n",
    "    alt_sl_sh_avg_b_dsavg[:,:,:] = np.mean(alt_sl_sh_avg_b_avg[:,:,:,:],  axis=3)\n",
    " \n",
    "    #(lev,lat) LT avg \n",
    "    SpEs_Occ_Fr_b_dsavgLT[:,:] = np.mean(SpEs_Occ_Fr_b_avgLT[:,:,:],  axis=2) #avg over ids dim ->(19, 96)\n",
    "    alt_sl_sh_avg_b_dsavgLT[:,:] = np.mean(alt_sl_sh_avg_b_avgLT[:,:,:],  axis=2) #avg over ids dim ->(25, 96)\n",
    "\n",
    "    #(lev,5'lat,LT), 5' lat bins \n",
    "    SpEs_Occ_Fr_bb_5d_dsavg[:,:,:] = np.mean(SpEs_Occ_Fr_bb_5d_avg[:,:,:,:],  axis=3) #avg over ids dim (avg all months)   =Whole Dataset avg   ->(19, 36, 48)\n",
    "    alt_sl_sh_avg_bb_5d_dsavg[:,:,:] = np.mean(alt_sl_sh_avg_bb_5d_avg[:,:,:,:],  axis=3)\n",
    "    \n",
    "    # (lev,lat,lon) \n",
    "    SpEsns_Occ_Fr_dsavg[:,:,:] = np.mean(SpEsns_Occ_Fr_avg[:,:,:,:],  axis=3) #avg over ids dim (avg all months)  => Whole Dataset avg (19,96,144)\n",
    "    alt_sl_aaavg[:,:,:] = np.mean(alt_sl_aavg,  axis=3)     #(19,96,144,3)->(19,96,144)\n",
    "\n",
    "    altavg = np.mean(altavg,  axis=1)\n",
    "    altavg_sl = np.mean(altavg_sl,  axis=1)\n",
    "    \n",
    "    # (lat,LT) \n",
    "    SpEs_Occ_Freq_llbav[:,:] = np.mean(SpEs_Occ_Freq_llba[:,:,:],  axis=2)    #avg over ids dim => (lat,LT)\n",
    "    # (lat,lon)\n",
    "    SpEsns_Occ_Freq_llav[:,:] = np.mean(SpEsns_Occ_Freq_lla[:,:,:],  axis=2)  #avg over ids dim => (lat,lon)\n",
    "    # (lat)\n",
    "    SpEsns_Occ_Freq_lat = np.mean(SpEsns_Occ_Freq_llav[:,:], axis=1)\n",
    "    \n",
    "    \n",
    "    ###__FoEs_ds_avg___###\n",
    "    if crit_freq_on==1:\n",
    "        foEs_m_av_ds[:,:] = np.nanmean( foEs_m_av_mth[:,:,:], axis=2 )\n",
    "        foEsns_m_av_ds[:,:] = np.nanmean( foEsns_m_av_mth[:,:,:], axis=2 )\n",
    "\n",
    "    \n",
    "    #===================================================================================================\n",
    "    end_time = time.process_time()\n",
    "    time_taken = end_time - start_time\n",
    "    time_taken_min = time_taken / 60.\n",
    "    print('========================================')\n",
    "    print('Calculation Time = ' + str(time_taken_min) + ' mins' )  \n",
    "\n",
    "    \n",
    "    #Save results to nc file\n",
    "    save_results(run_name, Monthfolderstr, lev, lev_sl, timear, lat, intlat, lon, LTar, LTlong, time_ar_2wk, ds_months, Zavg_sl, altavg, altavg_sl, times_str_min, times_str_max, SpEs_Occ_Fr_b_dsavg, SpEs_Occ_Fr_b_avg, SpEs_Occ_Fr_bb_5d_dsavg, SpEsns_Occ_Fr_dsavg, SpEs, alt_sl_sh_avg_b_dsavg, alt_sl_sh_avg_b_dsavgLT, alt_sl_sh_avg_bb_5d_dsavg, Mptdens_avv1_b_5d, Mptdens_std, Mptdens_nsstd, SpEsns_freq_time, SpEs_freq_time, Mptdens_avg, Mptdens_nsdiff, Mptdens_nsavg, SpEs_Occ_Freq_llbav, SpEsns_Occ_Freq_llav, SpEsns_Occ_Freq_lat  )\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f096020-fed9-41e1-a756-390c504ce612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf361e0-ab08-491f-a21a-8c1d8bbe91b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mynewkernel",
   "language": "python",
   "name": "mynewkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
