{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a62a9-4219-441b-a0c6-4a04b58eb1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# David Data - Dataset processing (into multidimensional bins)\n",
    "\n",
    "# Processing whole dataset as one, and seasons separately\n",
    "# Data on normal lat-lon coordinates \n",
    "\n",
    "# Using 96 lat bins (so resulting data has the same number of bins as WACCM output used in magnetic latitude interpolation calculation)\n",
    "\n",
    "# Original data has already filtered for Es. Where Es are detected, hmEs and s4s exist, else they are NaNs. So my processing says where not NaN, count as Es \n",
    "# Calculating Occurence freq over Lat-Lon only (as no altitude data where Es not detected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1a5df03-93ef-404b-b563-89132dd74c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501434/2282274303.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  jet = mcm.get_cmap('jet') if isinstance(mcm.get_cmap('jet'), str) else mcm.get_cmap('jet')\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import cftime\n",
    "import nc_time_axis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import ticker, cm\n",
    "from cftime import datetime \n",
    "import datetime as dt\n",
    "import matplotlib.colors as colors\n",
    "import math\n",
    "import random\n",
    "import matplotlib.cm as mcm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#jet = mcm.get_cmap('jet')\n",
    "jet = mcm.get_cmap('jet') if isinstance(mcm.get_cmap('jet'), str) else mcm.get_cmap('jet')\n",
    "import netCDF4 as nc\n",
    "import sys\n",
    "import os\n",
    "import psutil\n",
    "import netCDF4 as nc\n",
    "import cartopy.crs as ccrs # CRS stands for \"Coordinate reference systems\" for map projection\n",
    "from cartopy.crs import PlateCarree\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from dateutil import tz\n",
    "import pytz\n",
    "import time\n",
    "from time import process_time\n",
    "from tqdm import tqdm\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import dask\n",
    "%matplotlib inline \n",
    "import matplotlib.gridspec as gridspec\n",
    "#import line_profiler\n",
    "#%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9a99e5-1293-4acf-93f0-fefe5867c6ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Open WACCM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2d62c01-a7f6-4f41-af98-8aac938090fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Array lev = 1.3e-03hPa : 1.5e-05hPa (Z3 approx 89-129km, Alt approx 91-131km)\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Open WACCM dataset to define bins\n",
    "################################################################################\n",
    "\n",
    "# arrays sliced between chosen range (~90-130km) indices 42-60, 19 levels\n",
    "\n",
    "file1name='Nc_Files/SpE_Output/Wuhu_IonTr_run_SpE_Output_Dec-Feb.nc' \n",
    "wds = xr.open_dataset(file1name)\n",
    "\n",
    "wds_lat = wds['lat']\n",
    "wds_lon = wds['lon']\n",
    "\n",
    "lev_sl = wds['lev_sl']\n",
    "Zavg_sl = wds.variables['Zavg_sl'] \n",
    " \n",
    "altavg_sl = wds['altavg_sl']\n",
    "# altavg_sl.values # array([131.1492157 , 126.73989868, 122.75083923, 119.16303253,\n",
    "#        115.95503998, 113.10031128, 110.56510162, 108.3082428 ,\n",
    "#        106.28289795, 104.44081879, 102.7361145 , 101.12830353,\n",
    "#         99.58457184,  98.0800705 ,  96.59645081,  95.12115479,\n",
    "#         93.64645386,  92.16801453,  90.6837616 ])\n",
    "\n",
    "\n",
    "print('    Array lev = ' + str(\"%.1e\" % lev_sl[-1] ) + 'hPa : ' + str(\"%.1e\" % lev_sl[0] ) + 'hPa'\n",
    "           + ' (Z3 approx ' + str(\"%.0f\" % Zavg_sl[-1]) + '-' + str(\"%.0f\" % Zavg_sl[0] ) + 'km' + ',' \n",
    "           + ' Alt approx ' + str(\"%.0f\" % altavg_sl[-1]) + '-' + str(\"%.0f\" % altavg_sl[0] ) + 'km' + ')' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907d130-b573-4003-b12c-1b7d5bd3ff1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining Lon Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2509d6c-9656-4e13-9151-26e2bc93a41c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ################################################################################\n",
    "# # Lon bins -180 -> 180\n",
    "# ################################################################################\n",
    "\n",
    "# Updated value for a range of -180 to +180 degrees\n",
    "lon_upper_edge_last_bin = 180.0\n",
    "lon_bin_edges = np.append(np.arange(-180.0, 180.0, 2.5), lon_upper_edge_last_bin)\n",
    "lon_bin_midpoints = (lon_bin_edges[:-1] + lon_bin_edges[1:]) / 2\n",
    "\n",
    "# Other calculations (width, number of bins, etc.) remain the same\n",
    "lon_bin_widths = np.diff(lon_bin_edges)\n",
    "lon_average_bin_width = np.mean(lon_bin_widths)\n",
    "lon_num_bins = len(lon_bin_midpoints)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Lon Bin Edges (Lower and Upper):\")\n",
    "# for i in range(len(lon_bin_edges) - 1):\n",
    "#     print(f\"Bin {i + 1}: [{lon_bin_edges[i]}, {lon_bin_edges[i + 1]}]\")\n",
    "\n",
    "# print(\"\\nLon Bin Midpoints:\")\n",
    "# for i in range(len(lon_bin_midpoints)):\n",
    "#     print(f\"Lon Bin {i + 1} Midpoint: {lon_bin_midpoints[i]}\")\n",
    "\n",
    "# print(\"\\nLon Bin Widths:\", lon_bin_widths)\n",
    "# print(f\"Average Lon Bin Width: {lon_average_bin_width:.8f} degrees\")\n",
    "# print(f\"Number of Lon Bins: {lon_num_bins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a8c67-16ee-4196-8792-84240fdd2244",
   "metadata": {},
   "source": [
    "# Defining lat bins for maglat interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3236a45f-ae59-4cdb-9d37-96194533ce5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat Number of Bins: 96\n"
     ]
    }
   ],
   "source": [
    "# if maglatbins == 1:\n",
    "lat_bin_midpoints = wds['lat'].values\n",
    "lat_bin_widths = np.diff(lat_bin_midpoints)\n",
    "\n",
    "# Extend the array by one element with the same value as the last element\n",
    "lat_bin_widths_ext = np.append(lat_bin_widths, lat_bin_widths[-1])\n",
    "\n",
    "lat_bin_edges = np.zeros(lat_bin_midpoints.shape[0] + 1)\n",
    "lat_bin_edges[0:-1] = lat_bin_midpoints - lat_bin_widths_ext/2\n",
    "lat_bin_edges[-1] = lat_bin_midpoints[-1] + lat_bin_widths[-1]/2\n",
    "\n",
    "#lat_average_bin_width = np.mean(lat_bin_widths)\n",
    "lat_num_bins = len(lat_bin_midpoints)\n",
    "\n",
    "\n",
    "# # ##Print the results\n",
    "# print(\"Lat Bin Edges (Lower and Upper):\")\n",
    "# for i in range(len(lat_bin_edges) - 1):\n",
    "#     print(f\"Bin {i + 1}: [{lat_bin_edges[i]}, {lat_bin_edges[i + 1]}]\")\n",
    "\n",
    "# print(\"\\nLat Bin Midpoints:\")\n",
    "# for i in range(len(lat_bin_midpoints)):\n",
    "#     print(f\"Bin {i + 1} Midpoint: {lat_bin_midpoints[i]}\")\n",
    "\n",
    "# print(\"\\nLat Bin Widths:\", lat_bin_widths)\n",
    "# #print(f\"Lat Average Bin Width: {lat_average_bin_width:.6f} degrees\")\n",
    "print(f\"Lat Number of Bins: {lat_num_bins}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a3a96-58d1-4340-865c-c6727cedcfab",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Defining Altitude Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5edcf404-95ad-4ce4-81f5-8d5a38adced4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Zavg_70150 bins - Note first bin is at top\n",
    "# Bins between 70 and 150 km\n",
    "################################################################################\n",
    "\n",
    "\n",
    "wdss = xr.open_dataset('Nc_Files/ACP_CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_iontransport/ACP_CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_iontransport.cam.h2.0002-01-01-00000.nc')\n",
    "geopH = geopH = wdss['Z3'] / 1000\n",
    "Zavg = geopH.mean(('time','lat', 'lon'))\n",
    "\n",
    "index_70 = np.abs(Zavg - 70).argmin()\n",
    "index_150 = np.abs(Zavg - 150).argmin()\n",
    "\n",
    "Zavg_70150 = Zavg[int(index_150.item()):int(index_70.item())+1]\n",
    "#Zavg_70150\n",
    "\n",
    "\n",
    "Zavg_70150_bin_widths = np.diff(Zavg_70150.values)\n",
    "Zavg_70150_bin_edges = [Zavg_70150[0] - Zavg_70150_bin_widths[0] / 2] + [Zavg_70150[i] + Zavg_70150_bin_widths[i] / 2 for i in range(len(Zavg_70150_bin_widths))] + [Zavg_70150[-1] + Zavg_70150_bin_widths[-1] / 2]\n",
    "Zavg_70150_bin_midpoints = [(Zavg_70150_bin_edges[i] + Zavg_70150_bin_edges[i + 1]) / 2 for i in range(len(Zavg_70150_bin_edges) - 1)]\n",
    "Zavg_70150_num_bins = len(Zavg_70150_bin_midpoints)\n",
    "\n",
    "\n",
    "# # Print the bin edges and midpoints\n",
    "# print(\"Zavg_70150 Bin Edges (Lower and Upper):\")\n",
    "# for i in range(len(Zavg_70150_bin_edges) - 1):\n",
    "#     print(f\"Bin {i + 1}: [{Zavg_70150_bin_edges[i].values}, {Zavg_70150_bin_edges[i + 1].values}]\")\n",
    "\n",
    "# print(\"\\nZavg_70150 Bin Midpoints:\")\n",
    "# for i in range(len(Zavg_70150_bin_midpoints)):\n",
    "#     print(f\"Bin {i + 1} Midpoint: {Zavg_70150_bin_midpoints[i].values}\")\n",
    "\n",
    "# # Print the bin widths\n",
    "# print(\"\\nZavg_70150 Bin Widths:\")\n",
    "# for i in range(len(Zavg_70150_bin_widths)):\n",
    "#     print(f\"Bin {i + 1} Width: {Zavg_70150_bin_widths[i]}\")\n",
    "\n",
    "# print(f\"Number of Bins: {Zavg_70150_num_bins}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f858f-2706-424d-ba69-01500616e190",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load magnetic gridlines for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9a71a75-c13a-4f0e-8e29-7814373d4d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define magnetic latitude lines\n",
    "\n",
    "filename='Nc_Files/ACP_CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_iontransport/ACP_CESM213_FX2000_f19_f19_mg16_Na_Fe_Mg_iontransport.cam.h0.0001-06.nc' \n",
    "ds = xr.open_dataset(filename)\n",
    "ALATM = ds.variables['ALATM'] #Magnetic latitude at each geographic coordinate\n",
    "ALat = ds.variables['lat']\n",
    "ALon = ds.variables['lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8894e388-e690-4880-853b-df26e8e6941a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# COSMIC Data Loading (Lat-Lon, 2006-2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b0ad312-8e72-41fe-ada2-fbceebe3d719",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7657632,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmicnc = 'Nc_Files/s4max_files/COSMIC1_for_Leeds.h5'\n",
    "cds = xr.open_dataset(cosmicnc)\n",
    "\n",
    "Jdate = cds['Julian_date']\n",
    "lat = cds['Latitude']\n",
    "lon = cds['Longitude']\n",
    "hmEs = cds['hmEs']\n",
    "s4s = cds['s4s']\n",
    "\n",
    "phony_dim_0 = cds['phony_dim_0']\n",
    "\n",
    "s4s.shape #(7657632,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35c9701a-34f0-4ce2-b34c-24c90076c19c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7657632,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert julian date to datetime\n",
    "#======================================\n",
    "\n",
    "datetimes = pd.to_datetime(Jdate.values, unit='D', origin='julian')\n",
    "\n",
    "# datetime[0]  #Timestamp('2006-04-30 05:56:08.043825024')\n",
    "# datetime[-1]  #Timestamp('2019-12-10 12:39:50.466977536')\n",
    "datetimes.shape #(7657632,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22828cad-b877-49be-b3ee-279e7fc94865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print values of variables between a chosen range for info\n",
    "#======================================\n",
    "\n",
    "for index in range(1, 50):\n",
    "    lat_value = lat[index].values\n",
    "    lon_value = lon[index].values\n",
    "    hmEs_value = hmEs[index].values\n",
    "    s4s_value = s4s[index].values\n",
    "    datetime_value = datetimes[index]\n",
    "    Jdate_value = Jdate[index].values\n",
    "\n",
    "    #print(f\"Index {index}: dt = {datetime_value}, lat = {lat_value}, lon = {lon_value}, hmEs = {hmEs_value}, s4s = {s4s_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf547458-56fc-43ae-b50c-d0a3fc1c24c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort into consecutive time order\n",
    "#======================================\n",
    "\n",
    "\n",
    "cds_sorted = cds.sortby('Julian_date')\n",
    "\n",
    "# Extract sorted variables\n",
    "sorted_datetimes = pd.to_datetime(cds_sorted['Julian_date'].values, unit='D', origin='julian')\n",
    "sorted_lat = cds_sorted['Latitude'].values\n",
    "sorted_lon = cds_sorted['Longitude'].values\n",
    "sorted_hmEs = cds_sorted['hmEs'].values\n",
    "sorted_s4s = cds_sorted['s4s'].values\n",
    "\n",
    "\n",
    "# # Print a subset of sorted variables for indices 0 to 99\n",
    "# for i in range(50):\n",
    "#     print(f\"Ind {i}: dt = {sorted_datetimes[i]}, lat = {sorted_lat[i]}, lon = {sorted_lon[i]}, hmEs = {sorted_hmEs[i]}, s4s = {sorted_s4s[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab369e27-5ff2-4b52-850e-7deaaf531012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             datetime        lat         lon  hmEs  s4s\n",
      "0       2006-04-30 05:56:08.043825024  51.270003   95.375549   NaN  NaN\n",
      "1       2006-04-30 05:56:36.604321920  64.094526  123.877350   NaN  NaN\n",
      "2       2006-04-30 05:56:53.465184000  21.259120  137.635163   NaN  NaN\n",
      "3       2006-04-30 06:01:05.802982400  45.922146  119.382021   NaN  NaN\n",
      "4       2006-04-30 06:03:08.944861312  35.060482  143.047881   NaN  NaN\n",
      "...                               ...        ...         ...   ...  ...\n",
      "7657516 2019-12-10 11:30:26.465624576  23.987218   78.103606   NaN  NaN\n",
      "7657517 2019-12-10 11:39:52.366115840 -11.536251   79.228695   NaN  NaN\n",
      "7657518 2019-12-10 11:48:34.206978560 -49.524546   64.884119   NaN  NaN\n",
      "7657519 2019-12-10 12:39:28.187154944  49.982191 -112.757110   NaN  NaN\n",
      "7657520 2019-12-10 12:39:50.466977536  43.841069  -96.843928   NaN  NaN\n",
      "\n",
      "[7657521 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify indices where date/time = nan\n",
    "# Remove occultations where date/time = nan\n",
    "#======================================\n",
    "\n",
    "ind_to_remove = []\n",
    "\n",
    "for index in range(len(sorted_datetimes)):\n",
    "    if pd.isna(sorted_datetimes[index]):\n",
    "        lat_value = sorted_lat[index]\n",
    "        lon_value = sorted_lon[index]\n",
    "        hmEs_value = sorted_hmEs[index]\n",
    "        s4s_value = sorted_s4s[index]\n",
    "        \n",
    "        ind_to_remove.append(index)\n",
    "        \n",
    "        #print(f\"Index {index}: lat = {lat_value}, lon = {lon_value}, hmEs = {hmEs_value}, s4s = {s4s_value}\")\n",
    "\n",
    "## Create a new DataFrame without the specified indices\n",
    "filtered_df = pd.DataFrame({'datetime': sorted_datetimes, 'lat': sorted_lat, 'lon': sorted_lon, 'hmEs': sorted_hmEs, 's4s': sorted_s4s})\n",
    "\n",
    "# Use the separate variable ind_to_remove to remove indices\n",
    "filtered_df = filtered_df[~filtered_df.index.isin(ind_to_remove)]\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9068d951-b685-4e09-b93f-8600859d563d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load sliced data and re index so consecutive numbers\n",
    "#======================================\n",
    "\n",
    "fdatetimes = filtered_df['datetime']\n",
    "flat = filtered_df['lat']\n",
    "flon = filtered_df['lon']\n",
    "fhmEs = filtered_df['hmEs']\n",
    "fs4s = filtered_df['s4s']\n",
    "\n",
    "# Reset indices for consistency\n",
    "fdatetimes.reset_index(drop=True, inplace=True)\n",
    "flat.reset_index(drop=True, inplace=True)\n",
    "flon.reset_index(drop=True, inplace=True)\n",
    "fs4s.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5775a2-1bc1-44b4-b5f5-601fbd6881ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# COSMIC Data Processing: Occ Freq (lat-**lon**), Whole Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ab612c7-d6e2-44a6-bfd7-91eecd3ff8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7657521/7657521 [02:05<00:00, 61071.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Processing normal Lat Lon coordinates \n",
    "# Whole Dataset   \n",
    "#======================================\n",
    "\n",
    "averaging_period = 'Whole_Dataset'\n",
    "\n",
    "freq_lon = np.zeros((lat_num_bins, lon_num_bins))\n",
    "nmeas_lon = np.zeros((lat_num_bins, lon_num_bins))\n",
    "ocfr_lon = np.zeros((lat_num_bins, lon_num_bins))    \n",
    " \n",
    "ds_length = np.arange(fdatetimes.shape[0])\n",
    "\n",
    "for i in tqdm(ds_length):\n",
    "    current_lat = flat.values[i]\n",
    "    current_lon = flon.values[i]\n",
    "    current_s4max = fs4s.values[i]\n",
    "    current_time = fdatetimes[i]\n",
    "    lat_bin_index = np.digitize(current_lat, lat_bin_edges) - 1\n",
    "    lon_bin_index = np.digitize(current_lon, lon_bin_edges) - 1\n",
    "\n",
    "    nmeas_lon[lat_bin_index, lon_bin_index] += 1.\n",
    "\n",
    "    if not np.isnan(current_s4max):\n",
    "        freq_lon[lat_bin_index, lon_bin_index] += 1.\n",
    "\n",
    "ocfr_lon = (freq_lon / nmeas_lon) * 100.0\n",
    "\n",
    "###########################################################################################################################\n",
    "# Save occurrence frequency to nc file\n",
    "Ocfr_ds = xr.Dataset(\n",
    "    data_vars={\n",
    "        \"ocfr_lon\": (['latitude', 'longitude'], ocfr_lon),\n",
    "    },\n",
    "    coords={\n",
    "        #\"altitude\": Zavg_70150_bin_midpoints,\n",
    "        \"latitude\": lat_bin_midpoints,\n",
    "        \"longitude\": lon_bin_midpoints,\n",
    "    },\n",
    "    attrs={\n",
    "        'averaging_period': averaging_period,\n",
    "    }\n",
    ")\n",
    "\n",
    "output_directory = \"./Nc_Files/s4max/Daviddata/\"\n",
    "\n",
    "output_file = f\"{output_directory}Ocfr_Daviddata_{averaging_period}_ML.nc\"\n",
    "\n",
    "Ocfr_ds.to_netcdf(output_file)\n",
    "\n",
    "###########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d8410-ec6c-42e9-8c4c-e21259893487",
   "metadata": {
    "tags": []
   },
   "source": [
    "# COSMIC Data Processing: Occ Freq (lat-**lon**), Seasons Separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "180532a2-7259-4040-a69f-6fc501e5e7e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months [3, 4, 5]\n",
      "spring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7657521/7657521 [01:09<00:00, 110548.50it/s]\n",
      "/tmp/ipykernel_501434/2066068107.py:51: RuntimeWarning: invalid value encountered in divide\n",
      "  ocfr_lon = (freq_lon / nmeas_lon) * 100.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months [6, 7, 8]\n",
      "summer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7657521/7657521 [01:09<00:00, 110439.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months [9, 10, 11]\n",
      "autumn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7657521/7657521 [01:08<00:00, 111986.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months [12, 1, 2]\n",
      "winter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7657521/7657521 [01:08<00:00, 111437.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Processing Normal Lat Lon coordinates\n",
    "# Seasons separately\n",
    "#======================================\n",
    "\n",
    "# Define multiple sets of desired months\n",
    "all_desired_months = [ [3, 4, 5] , [6, 7, 8], [9, 10, 11] , [12, 1, 2] ]\n",
    "\n",
    "ds_length = np.arange(fdatetimes.shape[0])\n",
    "\n",
    "\n",
    "# Loop over each set of desired months\n",
    "for desired_months in all_desired_months:\n",
    "    print('Months ' + str(desired_months))\n",
    "\n",
    "    season = \"\"\n",
    "    if set(desired_months) <= {12, 1, 2}:\n",
    "        season = \"winter\"\n",
    "    elif set(desired_months) <= {3, 4, 5}:\n",
    "        season = \"spring\"\n",
    "    elif set(desired_months) <= {6, 7, 8}:\n",
    "        season = \"summer\"\n",
    "    elif set(desired_months) <= {9, 10, 11}:\n",
    "        season = \"autumn\"\n",
    "    else:\n",
    "        season = \"unknown\"\n",
    "        \n",
    "    print(season)\n",
    "    \n",
    "    averaging_period = 'Three-Month'\n",
    "    \n",
    "    freq_lon = np.zeros((lat_num_bins, lon_num_bins))\n",
    "    nmeas_lon = np.zeros((lat_num_bins, lon_num_bins))\n",
    "    ocfr_lon = np.zeros((lat_num_bins, lon_num_bins))    \n",
    " \n",
    "    for i in tqdm(ds_length):\n",
    "        current_lat = flat.values[i]\n",
    "        current_lon = flon.values[i]\n",
    "        current_s4max = fs4s.values[i]\n",
    "        current_time = fdatetimes[i]\n",
    "        current_month = current_time.month\n",
    "        \n",
    "        if current_month in desired_months:      \n",
    "            lat_bin_index = np.digitize(current_lat, lat_bin_edges) - 1\n",
    "            lon_bin_index = np.digitize(current_lon, lon_bin_edges) - 1\n",
    "\n",
    "            nmeas_lon[lat_bin_index, lon_bin_index] += 1.\n",
    "\n",
    "            if not np.isnan(current_s4max):\n",
    "                freq_lon[lat_bin_index, lon_bin_index] += 1.\n",
    "\n",
    "    ocfr_lon = (freq_lon / nmeas_lon) * 100.0\n",
    "\n",
    "    ###########################################################################################################################\n",
    "    # Save occurrence frequency to nc file\n",
    "    Ocfr_ds = xr.Dataset(\n",
    "        data_vars={\n",
    "            \"ocfr_lon\": (['latitude', 'longitude'], ocfr_lon),\n",
    "        },\n",
    "        coords={\n",
    "            \"latitude\": lat_bin_midpoints,\n",
    "            \"longitude\": lon_bin_midpoints,\n",
    "        },\n",
    "        attrs={\n",
    "            'averaging_period': averaging_period,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    output_directory = \"./Nc_Files/s4max/Daviddata/\"\n",
    "\n",
    "    output_file = f\"{output_directory}Ocfr_Daviddata_{season}_ML.nc\"\n",
    "    \n",
    "    Ocfr_ds.to_netcdf(output_file)\n",
    "\n",
    "    ###########################################################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49f435-c324-46ae-b4bf-67e3b41a2b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb65e02-60b7-4f67-a471-a02ba5e96e61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea2013-741d-4277-977d-461d6350bc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8779d6c-0c73-4aed-86c4-508ed71ae4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc72623-bd7a-4baa-a9c8-7e9f19c626e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82d58d-3877-4025-9a99-ea3df0b5ebc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad408e-a924-4a3c-a0fb-964d6a8e83c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39138720-b42c-4126-903a-35c87442ed12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae37f221-5730-4438-a320-ef4059b9b460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
